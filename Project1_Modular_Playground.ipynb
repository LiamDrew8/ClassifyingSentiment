{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e42ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_dir = 'data_reviews'\n",
    "    x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "    y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b0b7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into python\n",
    "x_train_df = pd.read_csv('data_reviews/x_train.csv')\n",
    "#concatenating review to make string processing easier\n",
    "tr_list_of_sentences = x_train_df['text'].str.cat(sep='\\n')\n",
    "#tr_list_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "ee721f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interesting model stuff\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "20902d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.read_csv('data_reviews/y_train.csv')\n",
    "y_tr_N = y_train_df.is_positive_sentiment.values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a8dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "719381bf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "ee7c2a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSteps:\\n1. Remove all non-alpha numeric characters from the string\\n2. Remove stop words\\n3. Correct spelling\\n\\n'"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Steps:\n",
    "1. Remove all non-alpha numeric characters from the string\n",
    "2. Remove stop words\n",
    "3. Correct spelling\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "c9ce3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all non-alpha numeric characters from the string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "e2f6180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using regex to remove non_alphanum\n",
    "def remove_non_alpha_num(reviews_string):\n",
    "    s = re.sub(r'[!]', ' ! ', reviews_string)\n",
    "    s = re.sub(r'[?]', ' ? ', s)\n",
    "    s = re.sub(r'[.]', ' ', s)\n",
    "    s = re.sub(r'[^A-Za-z\\'\\n\\s!?]+', '', s)\n",
    "    s = s.lower()\n",
    "    return s\n",
    "               \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "316216c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"can't do this\""
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unit Tests\n",
    "remove_non_alpha_num(\"can't.do this\")\n",
    "#remove_non_alpha_num(\"!?hello *&*^*^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "09187f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "ab7cedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "53a35b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = {word.replace(\"'\", '') for word in stop_words}\n",
    "toRemove = {\"not\", \"couldn't\", \"shouldn't\", \"didn't\", \"doesn't\", \"don't\", \"wasn't\", \"wouldn't\", \"won't\", \"again\"}\n",
    "for entry in toRemove:\n",
    "    stop_words.discard(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344670ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "20462bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "def remove_stop_words(reviews_string, remove_words):\n",
    "    reviews_list = reviews_string.split('\\n')\n",
    "    filtered_sentences = []\n",
    "    for review in reviews_list:\n",
    "        r = review.split()\n",
    "        filtered_words = [w for w in r if w not in remove_words]\n",
    "        filtered_sentence = ' '.join(filtered_words)\n",
    "        filtered_sentences.append(filtered_sentence)\n",
    "    \n",
    "    filtered_sentences = '\\n'.join(filtered_sentences)\n",
    "    return filtered_sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "f3316ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#using the approach from lab\n",
    "def tokenize_text(raw_text):\n",
    "    ''' Transform a plain-text string into a list of tokens\n",
    "    \n",
    "    We assume that *whitespace* divides tokens.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    raw_text : string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_tokens : list of strings\n",
    "        Each element is one token in the provided text\n",
    "    '''\n",
    "    list_of_tokens = raw_text.split() # split method divides on whitespace by default\n",
    "    for pp in range(len(list_of_tokens)):\n",
    "        cur_token = list_of_tokens[pp]\n",
    "        # Remove punctuation\n",
    "        for punc in ['_', '.', ',', '\"', '/']:\n",
    "            cur_token = cur_token.replace(punc, \"\")\n",
    "        # Turn to lower case\n",
    "        clean_token = cur_token.lower()\n",
    "        # Replace the cleaned token into the original list\n",
    "        list_of_tokens[pp] = clean_token\n",
    "    return list_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "3ba4519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!']"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text(\" ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "6fab8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "ac0afb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct spelling\n",
    "#https://pyspellchecker.readthedocs.io/en/latest/\n",
    "def correct_spelling(reviews_string):\n",
    "    reviews_list = reviews_string.split('\\n')\n",
    "    correctly_spelled_sentences = []\n",
    "    \n",
    "    speller = SpellChecker()\n",
    "    \n",
    "    for review in reviews_list:\n",
    "        words = review.split()\n",
    "        correctly_spelled_words = [speller.correction(word) if speller.correction(word) is not None else word for word in words]\n",
    "        correct_sentence = ' '.join(correctly_spelled_words)\n",
    "        correctly_spelled_sentences.append(correct_sentence)\n",
    "    \n",
    "    corrected_reviews_string = '\\n'.join(correctly_spelled_sentences)\n",
    "    return corrected_reviews_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "76dd5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "50ef51ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"beautiful\"])[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "99e6d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/part-speech-tagging-stop-words-using-nltk-python/\n",
    "#nltk.pos_tag([\"hello\"])[0][1][0].lower()\n",
    "def get_pos_tag(word):\n",
    "    word_tag = nltk.pos_tag([word])[0][1][0].lower()\n",
    "    tag_dict = {\"j\": wordnet.ADJ, \"n\": wordnet.NOUN, \"v\": wordnet.VERB, \"r\": wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(word_tag, \"n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c199d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331eafc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "9434e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(reviews_string):\n",
    "    reviews_list = reviews_string.split('\\n')\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    \n",
    "    lemmatized_text = [\" \".join([wnl.lemmatize(word, get_pos_tag(word)) for word in tokenize_text(review)]) for review in reviews_list]\n",
    "    \n",
    "    lemmatized_data = \"\\n\".join(lemmatized_text)\n",
    "    \n",
    "    return lemmatized_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb99fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "8d025b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code is from the Bag of Words Lab\n",
    "\n",
    "def create_tok_count(list_of_sentences):\n",
    "    \n",
    "    tok_count_dict = dict()\n",
    "\n",
    "    for line in list_of_sentences:\n",
    "        tok_list = tokenize_text(line)\n",
    "        for tok in tok_list:\n",
    "            if tok in tok_count_dict:\n",
    "                tok_count_dict[tok] += 1\n",
    "            else:\n",
    "                tok_count_dict[tok] = 1\n",
    "                    \n",
    "    return tok_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "011088e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "b1dcadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "def determine_sentiment(word):\n",
    "    afinn = Afinn()\n",
    "    score = afinn.score(word)\n",
    "    \n",
    "    if score > 0:\n",
    "        return 1  # Positive sentiment\n",
    "    elif score < 0:\n",
    "        return -1  # Negative sentiment\n",
    "    else:\n",
    "        return 0  # Neutral/Indeterminate sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "85be0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = \"okay\"\n",
    "result = determine_sentiment(word)\n",
    "print(result)  # 1 for positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "9c08d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_THRESHOLD = 2\n",
    "def build_vocab_list(reviews_string):\n",
    "    list_of_sentences = reviews_string.split('\\n')\n",
    "    \n",
    "    tok_count_dict = create_tok_count(list_of_sentences)\n",
    "    sorted_tokens = list(sorted(tok_count_dict, key=tok_count_dict.get, reverse=True))\n",
    "    \n",
    "    vocab_list = [w for w in sorted_tokens[:] if ((tok_count_dict[w] >= FREQ_THRESHOLD) or (determine_sentiment(w) != 0))]\n",
    "    #vocab_list = [w for w in sorted_tokens[:] if ((tok_count_dict[w] >= FREQ_THRESHOLD))]\n",
    "    \n",
    "    vocab_dict = dict()\n",
    "    for vocab_id, tok in enumerate(vocab_list):\n",
    "        vocab_dict[tok] = vocab_id\n",
    "    \n",
    "    return vocab_dict, len(list_of_sentences), len(vocab_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "2767db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list_of_sentences = reviews_string.split('\\n')\n",
    "    \n",
    "# tok_count_dict = create_tok_count(list_of_sentences)\n",
    "# sorted_tokens = list(sorted(tok_count_dict, key=tok_count_dict.get, reverse=True))\n",
    "\n",
    "# vocab_list = [w for w in sorted_tokens[:] if tok_count_dict[w] >= FREQ_THRESHOLD]\n",
    "\n",
    "# vocab_dict = dict()\n",
    "# for vocab_id, tok in enumerate(vocab_list):\n",
    "#     vocab_dict[tok] = vocab_id\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "ed3f9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok_count_dict[sorted_tokens[0]]\n",
    "# sorted_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "e5745a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_into_feature_vector(text, vocab_dict):\n",
    "    ''' Produce count feature vector for provided text\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    text : string\n",
    "        A string of raw text, representing a single 'review'\n",
    "    vocab_dict : dict with string keys\n",
    "        If token is in vocabulary, will exist as key in the dict\n",
    "        If token is not in vocabulary, will not be in the dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    count_V : 1D numpy array, shape (V,) = (n_vocab,)\n",
    "        Count vector, indicating how often each vocab word\n",
    "        appears in the provided text string\n",
    "    '''\n",
    "    V = len(vocab_dict.keys())\n",
    "    count_V = np.zeros(V)\n",
    "    for tok in tokenize_text(text):\n",
    "        if tok in vocab_dict:\n",
    "            vv = vocab_dict[tok]\n",
    "            count_V[vv] += 1\n",
    "    return count_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb78b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "beb6b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT TOUCH THESE: THEY TAKE A LONG TIME TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "242e52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(tr_list_of_sentences):\n",
    "    original_review_string = tr_list_of_sentences\n",
    "    reviews_string = remove_non_alpha_num(tr_list_of_sentences)\n",
    "    reviews_string = correct_spelling(reviews_string)\n",
    "    reviews_string = lemmatize_words(reviews_string)\n",
    "    reviews_string = remove_stop_words(reviews_string, stop_words)\n",
    "    return reviews_string, original_review_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "55ebb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews_string, original_review_string = preprocess_string(tr_list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# original_review_string = tr_list_of_sentences\n",
    "# reviews_string = remove_non_alpha_num(tr_list_of_sentences)\n",
    "# reviews_string = correct_spelling(reviews_string)\n",
    "# reviews_string = lemmatize_words(reviews_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "885238cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_string = remove_stop_words(reviews_string, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "d7d043a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_review_string = tr_list_of_sentences\n",
    "# reviews_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "b8217fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think I have just improved the text processing. Let's see what models can do for me now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f8c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "03414361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "81e99d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 5000\n",
    "vectorizer = CountVectorizer(max_features = MAX_FEATURES)\n",
    "X = vectorizer.fit_transform(reviews_string.split(\"\\n\"))\n",
    "x_prepared_NV = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "a6d073d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "906f8005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "52989e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 3725)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "2147868b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "17195dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict, N, V = build_vocab_list(reviews_string)\n",
    "x_prepared_NV = np.zeros((N, V))\n",
    "for nn, raw_text_line in enumerate(reviews_string.split(\"\\n\")):\n",
    "    x_prepared_NV[nn] = transform_text_into_feature_vector(raw_text_line, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df88ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d365119",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b78f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae9bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30342bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf8a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "55c0bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "SEED = 2\n",
    "FOLDS = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c6126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "fe8e178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cRange = loguniform(1e-3, 1e3)\n",
    "tol = [0, 1e-1,1e-2,1e-3,1e-4,1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "135dd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver 'lbfgs' does not support an l1 penalty\n",
    "distributions = {\n",
    "    'C': cRange,\n",
    "    'penalty': ['l2']\n",
    "    #'tol': tol,\n",
    "    #'fit_intercept': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a3c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "b33aa2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_search = RandomizedSearchCV(\n",
    "    estimator = model,\n",
    "    param_distributions = distributions,\n",
    "    scoring = 'roc_auc',\n",
    "    cv = FOLDS,\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "45765969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "3ffacf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-06, 2.15443469e-05, 4.64158883e-04, 1.00000000e-02,\n",
       "       2.15443469e-01, 4.64158883e+00, 1.00000000e+02, 2.15443469e+03,\n",
       "       4.64158883e+04, 1.00000000e+06])"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_grid = np.logspace(-6, 6, 10)\n",
    "C_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895496d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24936a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de420a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "ebface95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=20, estimator=LogisticRegression(max_iter=300),\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f84041baad0&gt;,\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=20, estimator=LogisticRegression(max_iter=300),\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f84041baad0&gt;,\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=20, estimator=LogisticRegression(max_iter=300),\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f84041baad0>,\n",
       "                                        'penalty': ['l2']},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_search.fit(x_prepared_NV, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "1ccc43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best score: 0.8945833333333333: using my dictionary\n",
    "#0.8894114583333333 using CountVectorize()\n",
    "\n",
    "#After cleaning data:\n",
    "#using CountVectorize(): 0.8946927083333335\n",
    "#Using my dictionary: 0.8967708333333334\n",
    "\n",
    "#trying again:\n",
    "#using my dictionary: 0.8929\n",
    "#using countvectorize(): 0.888\n",
    "\n",
    "#no apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "fb86e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.5381114029010693, 'penalty': 'l2'}\n",
      "Best score: 0.8946111111111111\n",
      "Best pipeline: LogisticRegression(C=0.5381114029010693, max_iter=300)\n",
      "Index of best pipeline: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>split15_test_score</th>\n",
       "      <th>split16_test_score</th>\n",
       "      <th>split17_test_score</th>\n",
       "      <th>split18_test_score</th>\n",
       "      <th>split19_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104437</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.526177</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.5261767150507294, 'penalty': 'l2'}</td>\n",
       "      <td>0.937222</td>\n",
       "      <td>0.921111</td>\n",
       "      <td>0.938889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900556</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.941111</td>\n",
       "      <td>0.873889</td>\n",
       "      <td>0.894569</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.251091</td>\n",
       "      <td>0.020943</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>8.896969</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 8.896969297358647, 'penalty': 'l2'}</td>\n",
       "      <td>0.904444</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.919722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.850278</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.883583</td>\n",
       "      <td>0.032159</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028677</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.0016757857978465414, 'penalty': 'l2'}</td>\n",
       "      <td>0.869444</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834167</td>\n",
       "      <td>0.758889</td>\n",
       "      <td>0.828056</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.878056</td>\n",
       "      <td>0.879444</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.824417</td>\n",
       "      <td>0.054086</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.107326</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.538111</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.5381114029010693, 'penalty': 'l2'}</td>\n",
       "      <td>0.937222</td>\n",
       "      <td>0.921389</td>\n",
       "      <td>0.938889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900278</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>0.908611</td>\n",
       "      <td>0.930833</td>\n",
       "      <td>0.941111</td>\n",
       "      <td>0.873611</td>\n",
       "      <td>0.894611</td>\n",
       "      <td>0.035273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.747402</td>\n",
       "      <td>0.045568</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>803.043292</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 803.0432924227676, 'penalty': 'l2'}</td>\n",
       "      <td>0.839722</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.799167</td>\n",
       "      <td>0.864722</td>\n",
       "      <td>0.801111</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>0.818611</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.040257</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.056573</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>196.865769</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 196.8657686540476, 'penalty': 'l2'}</td>\n",
       "      <td>0.850556</td>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850833</td>\n",
       "      <td>0.792222</td>\n",
       "      <td>0.817222</td>\n",
       "      <td>0.879722</td>\n",
       "      <td>0.830833</td>\n",
       "      <td>0.916389</td>\n",
       "      <td>0.840556</td>\n",
       "      <td>0.840958</td>\n",
       "      <td>0.037142</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050629</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01822486874332968, 'penalty': 'l2'}</td>\n",
       "      <td>0.901667</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.913611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864444</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.872778</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.901111</td>\n",
       "      <td>0.857222</td>\n",
       "      <td>0.852014</td>\n",
       "      <td>0.048496</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.069676</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.08148220408629418, 'penalty': 'l2'}</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.934722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885556</td>\n",
       "      <td>0.818056</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.889444</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.921667</td>\n",
       "      <td>0.871389</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>0.041186</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.661188</td>\n",
       "      <td>0.216268</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>64.408414</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 64.40841410554434, 'penalty': 'l2'}</td>\n",
       "      <td>0.866944</td>\n",
       "      <td>0.871389</td>\n",
       "      <td>0.889722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862778</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>0.833889</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.926944</td>\n",
       "      <td>0.852222</td>\n",
       "      <td>0.857444</td>\n",
       "      <td>0.034618</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.876610</td>\n",
       "      <td>0.120858</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>423.831727</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 423.83172733390427, 'penalty': 'l2'}</td>\n",
       "      <td>0.841389</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842778</td>\n",
       "      <td>0.778611</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.871944</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.912222</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.830236</td>\n",
       "      <td>0.040175</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time     param_C  \\\n",
       "0       0.104437      0.012375         0.001782        0.000351    0.526177   \n",
       "1       0.251091      0.020943         0.002006        0.000325    8.896969   \n",
       "2       0.028677      0.001793         0.001707        0.000152    0.001676   \n",
       "3       0.107326      0.011813         0.001903        0.000323    0.538111   \n",
       "4       0.747402      0.045568         0.002425        0.000250  803.043292   \n",
       "5       0.629825      0.056573         0.002163        0.000300  196.865769   \n",
       "6       0.050629      0.010272         0.002679        0.000788    0.018225   \n",
       "7       0.069676      0.007671         0.002249        0.000391    0.081482   \n",
       "8       0.661188      0.216268         0.003150        0.000776   64.408414   \n",
       "9       0.876610      0.120858         0.002610        0.000628  423.831727   \n",
       "\n",
       "  param_penalty                                         params  \\\n",
       "0            l2     {'C': 0.5261767150507294, 'penalty': 'l2'}   \n",
       "1            l2      {'C': 8.896969297358647, 'penalty': 'l2'}   \n",
       "2            l2  {'C': 0.0016757857978465414, 'penalty': 'l2'}   \n",
       "3            l2     {'C': 0.5381114029010693, 'penalty': 'l2'}   \n",
       "4            l2      {'C': 803.0432924227676, 'penalty': 'l2'}   \n",
       "5            l2      {'C': 196.8657686540476, 'penalty': 'l2'}   \n",
       "6            l2    {'C': 0.01822486874332968, 'penalty': 'l2'}   \n",
       "7            l2    {'C': 0.08148220408629418, 'penalty': 'l2'}   \n",
       "8            l2      {'C': 64.40841410554434, 'penalty': 'l2'}   \n",
       "9            l2     {'C': 423.83172733390427, 'penalty': 'l2'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  ...  \\\n",
       "0           0.937222           0.921111           0.938889  ...   \n",
       "1           0.904444           0.909722           0.919722  ...   \n",
       "2           0.869444           0.848333           0.883333  ...   \n",
       "3           0.937222           0.921389           0.938889  ...   \n",
       "4           0.839722           0.842222           0.851667  ...   \n",
       "5           0.850556           0.854444           0.871667  ...   \n",
       "6           0.901667           0.875556           0.913611  ...   \n",
       "7           0.931667           0.900000           0.934722  ...   \n",
       "8           0.866944           0.871389           0.889722  ...   \n",
       "9           0.841389           0.847500           0.862222  ...   \n",
       "\n",
       "   split13_test_score  split14_test_score  split15_test_score  \\\n",
       "0            0.900556            0.852778            0.858611   \n",
       "1            0.884444            0.850278            0.851667   \n",
       "2            0.834167            0.758889            0.828056   \n",
       "3            0.900278            0.852778            0.858611   \n",
       "4            0.832778            0.772500            0.799167   \n",
       "5            0.850833            0.792222            0.817222   \n",
       "6            0.864444            0.784722            0.839444   \n",
       "7            0.885556            0.818056            0.846389   \n",
       "8            0.862778            0.814167            0.833889   \n",
       "9            0.842778            0.778611            0.804444   \n",
       "\n",
       "   split16_test_score  split17_test_score  split18_test_score  \\\n",
       "0            0.907778            0.930556            0.941111   \n",
       "1            0.897500            0.894167            0.939167   \n",
       "2            0.838889            0.878056            0.879444   \n",
       "3            0.908611            0.930833            0.941111   \n",
       "4            0.864722            0.801111            0.907778   \n",
       "5            0.879722            0.830833            0.916389   \n",
       "6            0.872778            0.905556            0.901111   \n",
       "7            0.889444            0.925000            0.921667   \n",
       "8            0.885000            0.852778            0.926944   \n",
       "9            0.871944            0.816667            0.912222   \n",
       "\n",
       "   split19_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.873889         0.894569        0.035301                2  \n",
       "1            0.862500         0.883583        0.032159                3  \n",
       "2            0.831667         0.824417        0.054086                9  \n",
       "3            0.873611         0.894611        0.035273                1  \n",
       "4            0.818611         0.822000        0.040257               10  \n",
       "5            0.840556         0.840958        0.037142                7  \n",
       "6            0.857222         0.852014        0.048496                6  \n",
       "7            0.871389         0.876986        0.041186                4  \n",
       "8            0.852222         0.857444        0.034618                5  \n",
       "9            0.830556         0.830236        0.040175                8  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best params:', curr_search.best_params_)\n",
    "print('Best score:', curr_search.best_score_)\n",
    "print('Best pipeline:', curr_search.best_estimator_)\n",
    "print('Index of best pipeline:', curr_search.best_index_)\n",
    "results=pd.DataFrame(curr_search.cv_results_)\n",
    "results #see results of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "5f968c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.526177\n",
       "1      8.896969\n",
       "2      0.001676\n",
       "3      0.538111\n",
       "4    803.043292\n",
       "5    196.865769\n",
       "6      0.018225\n",
       "7      0.081482\n",
       "8     64.408414\n",
       "9    423.831727\n",
       "Name: param_C, dtype: object"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['param_C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "55e384f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.894569\n",
       "1    0.883583\n",
       "2    0.824417\n",
       "3    0.894611\n",
       "4    0.822000\n",
       "5    0.840958\n",
       "6    0.852014\n",
       "7    0.876986\n",
       "8    0.857444\n",
       "9    0.830236\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43474a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "ecec203e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['param_C'], results['mean_test_score'], 'ro', label='mean_test_score on validation set')\n",
    "# plt.plot(np.log10(C_grid), va_bce_list, 'rs-', label='valid BCE')\n",
    "\n",
    "# plt.plot(np.log10(C_grid), tr_err_list, 'b:', label='train err')\n",
    "# plt.plot(np.log10(C_grid), va_err_list, 'r:', label='valid err')\n",
    "\n",
    "plt.ylabel('error')\n",
    "plt.xlabel(\"$\\log_{10} C$\");\n",
    "plt.legend(bbox_to_anchor=(1.5, 0.5)) # make legend outside plot\n",
    "plt.ylim([0.8, 1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17bfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "f15870d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a leaderboard score:\n",
    "x_test_df = pd.read_csv('data_reviews/x_test.csv')\n",
    "test_list_of_sentences = x_test_df['text'].str.cat(sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "92db3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a806eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_of_sentences, blah = preprocess_string(test_list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f1b1c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_list_of_sentences = remove_non_alpha_num(test_list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d6c9a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_list_of_sentences = correct_spelling(test_list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d90e178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_list_of_sentences = remove_stop_words(test_list_of_sentences, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "47cf2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determining test data size\n",
    "list_of_sentences2 = test_list_of_sentences.split('\\n')\n",
    "Z = len(list_of_sentences2)\n",
    "x_tr_ZV = np.zeros((Z, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e0165d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn2, raw_text_line2 in enumerate(list_of_sentences2):\n",
    "    x_tr_ZV[nn2] = transform_text_into_feature_vector(raw_text_line2, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0b8352f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_N = curr_search.predict_proba(x_tr_ZV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b71c2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"yproba1_test.txt\", yhat_test_N[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3fc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6d33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "435f5638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "train_predictions = curr_search.predict(x_prepared_NV)\n",
    "probas = curr_search.predict_proba(x_prepared_NV)\n",
    "b = ~np.equal(train_predictions, y_tr_N)\n",
    "indices = np.flatnonzero(b)\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3ae8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f951080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacc737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "de07883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Butchered Review:\n",
      "really want plantronics right one many issue good\n",
      "Original Review:\n",
      "I really wanted the Plantronics 510 to be the right one, but it has too many issues for me.The good\n",
      "Probability: [0.15517271 0.84482729]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "excellent starter wireless headset\n",
      "Original Review:\n",
      "Excellent starter wireless headset.\n",
      "Probability: [0.13138337 0.86861663]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "i'd expect well consumer experience motorola\n",
      "Original Review:\n",
      "All in all, I'd expected a better consumer experience from Motorola.\n",
      "Probability: [0.49157828 0.50842172]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "phone year tell not great\n",
      "Original Review:\n",
      "I have had this phone for over a year now, and I will tell you, its not that great.\n",
      "Probability: [0.31324782 0.68675218]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "loudspeaker option great bumper light appeal\n",
      "Original Review:\n",
      "The loudspeaker option is great, the bumpers with the lights is very ... appealing.\n",
      "Probability: [0.13213064 0.86786936]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "plan use car forget\n",
      "Original Review:\n",
      "If you plan to use this in a car forget about it.\n",
      "Probability: [0.46015418 0.53984582]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "internet access fine rare instance work\n",
      "Original Review:\n",
      "The internet access was fine, it the rare instance that it worked.\n",
      "Probability: [0.41437743 0.58562257]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "work right atleast\n",
      "Original Review:\n",
      "wont work right or atleast for me.\n",
      "Probability: [0.30432828 0.69567172]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "however need well instruction\n",
      "Original Review:\n",
      "However I needed some better instructions.\n",
      "Probability: [0.49162695 0.50837305]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "like loud buzzing override conversation phone !\n",
      "Original Review:\n",
      "If you like a loud buzzing to override all your conversations, then this phone is for you!\n",
      "Probability: [0.40849713 0.59150287]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not good enough price\n",
      "Original Review:\n",
      "Not good enough for the price.\n",
      "Probability: [0.31571639 0.68428361]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "purchase different case\n",
      "Original Review:\n",
      "I had to purchase a different case.\n",
      "Probability: [0.35050119 0.64949881]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "product cost much one expect work far well great ease thing\n",
      "Original Review:\n",
      "For a product that costs as much as this one does, I expect it to work far better and with greater ease than this thing does.\n",
      "Probability: [0.34138691 0.65861309]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "much hype phone assume best mistake\n",
      "Original Review:\n",
      "There was so much hype over this phone that I assumed it was the best, my mistake.\n",
      "Probability: [0.41299513 0.58700487]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "plan order\n",
      "Original Review:\n",
      "Plan on ordering from them again and again.\n",
      "Probability: [0.52484282 0.47515718]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "get signal version phone won't\n",
      "Original Review:\n",
      "Gets a signal when other Verizon phones won't.\n",
      "Probability: [0.50325281 0.49674719]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "everything description say would\n",
      "Original Review:\n",
      "It does everything the description said it would.\n",
      "Probability: [0.50470878 0.49529122]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "virgin wireless rock cheap little phone !\n",
      "Original Review:\n",
      "Virgin Wireless rocks and so does this cheap little phone!\n",
      "Probability: [0.56446865 0.43553135]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "really like product motorola allot clearer ear piece mic\n",
      "Original Review:\n",
      "I really like this product over the Motorola because it is allot clearer on the ear piece and the mic.\n",
      "Probability: [0.65191067 0.34808933]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "much less jawbone go replace\n",
      "Original Review:\n",
      "Much less than the jawbone I was going to replace it with.\n",
      "Probability: [0.55639679 0.44360321]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "get extra minute carry call not get cut\n",
      "Original Review:\n",
      "You get extra minutes so that you can carry out the call and not get cut off.\"\n",
      "Probability: [0.73881931 0.26118069]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "bought save lot money\n",
      "Original Review:\n",
      "So I bought about 10 of these and saved alot of money.\n",
      "Probability: [0.6165722 0.3834278]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "ear occupy background not distract\n",
      "Original Review:\n",
      "Because both ears are occupied, background is not distracting at all.\n",
      "Probability: [0.7366355 0.2633645]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "span hour two people exclaim whoa new phone ? ! ?\n",
      "Original Review:\n",
      "In the span of an hour, I had two people exclaim \"Whoa - is that the new phone on TV?!?\n",
      "Probability: [0.74282643 0.25717357]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not problem item would order need\n",
      "Original Review:\n",
      "I did not have any problem with this item and would order it again if needed.\n",
      "Probability: [0.88184272 0.11815728]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "color even prettier thought would graphic incredibly sharp\n",
      "Original Review:\n",
      "The color is even prettier than I thought it would be, and the graphics are incredibly sharp.\n",
      "Probability: [0.5577276 0.4422724]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "small don't even realize get use\n",
      "Original Review:\n",
      "It is so small and you don't even realize that it is there after a while of getting used to it.\n",
      "Probability: [0.56432499 0.43567501]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "case would order another\n",
      "Original Review:\n",
      "I own 2 of these cases and would order another.\n",
      "Probability: [0.56678342 0.43321658]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "usually don't like headband one lightweight doesn't mess hair\n",
      "Original Review:\n",
      "I usually don't like headbands but this one is very lightweight & doesn't mess up my hair.\n",
      "Probability: [0.67333611 0.32666389]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "i'm still infatuate phone\n",
      "Original Review:\n",
      "I'm still infatuated with this phone.\n",
      "Probability: [0.51171369 0.48828631]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "pair iphone could not happier far\n",
      "Original Review:\n",
      "I am pairing this with my iphone, and I could not be happier with it so far.\n",
      "Probability: [0.57157002 0.42842998]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "windresistant\n",
      "Original Review:\n",
      "Very wind-resistant.\n",
      "Probability: [0.5 0.5]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "graphic far best part game\n",
      "Original Review:\n",
      "Graphics is far from the best part of the game.  \n",
      "Probability: [0.19486321 0.80513679]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "second movie\n",
      "Original Review:\n",
      "That was done in the second movie.  \n",
      "Probability: [0.45685134 0.54314866]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "delete film mind !\n",
      "Original Review:\n",
      "DELETE this film from your mind!  \n",
      "Probability: [0.3966213 0.6033787]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "character 'stagey' storyline lot like stage farce\n",
      "Original Review:\n",
      "The characters were very 'stagey' and the storyline was a lot like a stage farce.  \n",
      "Probability: [0.49480412 0.50519588]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "set\n",
      "Original Review:\n",
      "1/10 - and only because there is no setting for 0/10.  \n",
      "Probability: [0.39590552 0.60409448]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "direct sloppy best\n",
      "Original Review:\n",
      "The directing is sloppy at best.  \n",
      "Probability: [0.41446444 0.58553556]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "highly recommend\n",
      "Original Review:\n",
      "Highly unrecommended.  \n",
      "Probability: [0.20603645 0.79396355]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "film less expansive\n",
      "Original Review:\n",
      "Filmiing was less expansive.  \n",
      "Probability: [0.44347469 0.55652531]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "find well movie youtube\n",
      "Original Review:\n",
      "You can find better movies at youtube.  \n",
      "Probability: [0.22718734 0.77281266]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "least say act well\n",
      "Original Review:\n",
      "The least said about the acting the better.  \n",
      "Probability: [0.38054303 0.61945697]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "fail convey broad sweep landscape great part original\n",
      "Original Review:\n",
      "It failed to convey the broad sweep of landscapes that were a great part of the original.  \n",
      "Probability: [0.24160168 0.75839832]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "place good film garbage\n",
      "Original Review:\n",
      "The only place good for this film is in the garbage.  \n",
      "Probability: [0.19598862 0.80401138]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "lead man charismafree\n",
      "Original Review:\n",
      "The lead man is charisma-free.  \n",
      "Probability: [0.4977251 0.5022749]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "drive barking mad !\n",
      "Original Review:\n",
      "It will drive you barking mad!  \n",
      "Probability: [0.4052934 0.5947066]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "it's shame see good actor like thompson james make living mess like\n",
      "Original Review:\n",
      "It's a shame to see good actors like Thomerson and James make a living in a mess like this.  \n",
      "Probability: [0.22297711 0.77702289]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "act whole cast could put scale balance perfectly overact interact\n",
      "Original Review:\n",
      "The acting by the whole cast could be put on a scale and balanced perfectly between overacting and underacting.  \n",
      "Probability: [0.49249732 0.50750268]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "left shatter experience watch film take good two hour fully recover\n",
      "Original Review:\n",
      "I was left shattered from the experience of watching this 'film' and I took a good two hours to fully recover.  \n",
      "Probability: [0.44581595 0.55418405]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "great disappointment\n",
      "Original Review:\n",
      "All in all, a great disappointment.  \n",
      "Probability: [0.29693575 0.70306425]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "see movie free\n",
      "Original Review:\n",
      "i wouldnt see this movie again for free.  \n",
      "Probability: [0.47898954 0.52101046]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "guy say he's well dialogue pot plant right\n",
      "Original Review:\n",
      "The guy who said he's had better dialogue with his potted plants has it right.  \n",
      "Probability: [0.40986729 0.59013271]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "movie definitely average rent\n",
      "Original Review:\n",
      "But this movie is definitely a below average rent.  \n",
      "Probability: [0.43441903 0.56558097]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "force like everything movie\n",
      "Original Review:\n",
      "It was forced, like everything in this movie.  \n",
      "Probability: [0.38460819 0.61539181]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "superficial movie give feel watch play rather film\n",
      "Original Review:\n",
      "It was a very superficial movie and it gave me the feeling that I was watching play rather than a film.  \n",
      "Probability: [0.48252644 0.51747356]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "accent absolutely abysmal !\n",
      "Original Review:\n",
      "And the accents are absolutely abysmal!  \n",
      "Probability: [0.47783158 0.52216842]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "long whiny pointless\n",
      "Original Review:\n",
      "Long, whiny and pointless.  \n",
      "Probability: [0.49218076 0.50781924]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "go see !\n",
      "Original Review:\n",
      "GO AND SEE IT!  \n",
      "Probability: [0.51674777 0.48325223]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "kind money waste properly\n",
      "Original Review:\n",
      "This is the kind of money that is wasted properly.  \n",
      "Probability: [0.77756712 0.22243288]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "predictable not bad watch\n",
      "Original Review:\n",
      "Predictable, but not a bad watch.  \n",
      "Probability: [0.99034675 0.00965325]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "struggle find anything bad say\n",
      "Original Review:\n",
      "I struggle to find anything bad to say about it.  \n",
      "Probability: [0.75881825 0.24118175]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "anyone right mind ask anything movie ?\n",
      "Original Review:\n",
      "How can anyone in their right mind ask for anything more from a movie than this?  \n",
      "Probability: [0.52068057 0.47931943]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "last minute movie also not bad well\n",
      "Original Review:\n",
      "The last 15 minutes of movie are also not bad as well.  \n",
      "Probability: [0.97936186 0.02063814]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "three visually appeal movie i've ever see\n",
      "Original Review:\n",
      "Three of the most visually appealing movies i've ever seen.  \n",
      "Probability: [0.58763049 0.41236951]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "first movie i've give year\n",
      "Original Review:\n",
      "This if the first movie I've given a 10 to in years.  \n",
      "Probability: [0.53950699 0.46049301]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "advise look\n",
      "Original Review:\n",
      "I advise you to look out for it.  \n",
      "Probability: [0.6079548 0.3920452]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "don't miss\n",
      "Original Review:\n",
      "Don't miss it.  \n",
      "Probability: [0.64207222 0.35792778]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "cinematography simply stun say least fix nothing not stateoftheart\n",
      "Original Review:\n",
      "The cinematography is simply stunning (to say the least) and the fx are nothing if not state-of-the-art.  \n",
      "Probability: [0.84720016 0.15279984]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "never forget\n",
      "Original Review:\n",
      "I will never forget it now.  \n",
      "Probability: [0.58932833 0.41067167]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "waste money game\n",
      "Original Review:\n",
      "Waste your money on this game.  \n",
      "Probability: [0.818118 0.181882]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "could use exemplar set designer\n",
      "Original Review:\n",
      "They could be used as exemplars for any set designer.  \n",
      "Probability: [0.51341685 0.48658315]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "go rent\n",
      "Original Review:\n",
      "Go rent it.  \n",
      "Probability: [0.60559003 0.39440997]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "spoiler whatever else can't say surface superbly craft\n",
      "Original Review:\n",
      "***SPOILERS*** Whatever else can (or can't) be said about it, SURFACE is superbly crafted.  \n",
      "Probability: [0.60281087 0.39718913]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "enough not say remarkable animation film\n",
      "Original Review:\n",
      "Enough can not be said of the remarkable animation in this film.  \n",
      "Probability: [0.5834094 0.4165906]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "fact it's hard remember part ray charles act not played man\n",
      "Original Review:\n",
      "\" In fact, it's hard to remember that the part of Ray Charles is being acted, and not played by the man himself.  \n",
      "Probability: [0.5027747 0.4972253]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "aerial scene wellcome\n",
      "Original Review:\n",
      "The aerial scenes were well-done.  \n",
      "Probability: [0.53089888 0.46910112]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "long time didn't see charismatic actor screen\n",
      "Original Review:\n",
      "It was a long time that i didn't see a so charismatic actor on screen.  \n",
      "Probability: [0.61019064 0.38980936]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "soundtrack wasn't terrible either\n",
      "Original Review:\n",
      "The soundtrack wasn't terrible, either.  \n",
      "Probability: [0.8880848 0.1119152]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not much dialogue not much music whole film shot elaborately aesthetically like sculpture\n",
      "Original Review:\n",
      "Not much dialogue, not much music, the whole film was shot as elaborately and aesthetically like a sculpture.  \n",
      "Probability: [0.92203775 0.07796225]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "\n",
      "Original Review:\n",
      "10/10  \n",
      "Probability: [0.5 0.5]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "anyway plot flow smoothly malebonding scene hoot\n",
      "Original Review:\n",
      ":) Anyway, the plot flowed smoothly and the male-bonding scenes were a hoot.  \n",
      "Probability: [0.62570698 0.37429302]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "\n",
      "Original Review:\n",
      "10/10  \n",
      "Probability: [0.5 0.5]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "give one look\n",
      "Original Review:\n",
      "Give this one a look.  \n",
      "Probability: [0.6773845 0.3226155]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "don't think disappointed\n",
      "Original Review:\n",
      "I don't think you will be disappointed.  \n",
      "Probability: [0.87299668 0.12700332]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not cult cult classic\n",
      "Original Review:\n",
      "It is not just a cult... it is a cult CLASSIC.  \n",
      "Probability: [0.50668281 0.49331719]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not scream not masculine right\n",
      "Original Review:\n",
      "Not too screamy not to masculine but just right.  \n",
      "Probability: [0.913309 0.086691]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "film not easily forgotten\n",
      "Original Review:\n",
      "A film not easily forgotten.  \n",
      "Probability: [0.73922009 0.26077991]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "i'd advise anyone go see\n",
      "Original Review:\n",
      "I'd advise anyone to go and see it.  \n",
      "Probability: [0.52592849 0.47407151]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "grandmother make roast chicken well one\n",
      "Original Review:\n",
      "Any grandmother can make a roasted chicken better than this one.\n",
      "Probability: [0.49274011 0.50725989]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "drive get\n",
      "Original Review:\n",
      "it was a drive to get there.\n",
      "Probability: [0.33557403 0.66442597]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "pale color instead nice char flavor\n",
      "Original Review:\n",
      "It was a pale color instead of nice and char and has NO flavor.\n",
      "Probability: [0.33783851 0.66216149]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "scallop dish quite appal value well\n",
      "Original Review:\n",
      "The scallop dish is quite appalling for value as well.\n",
      "Probability: [0.46010011 0.53989989]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "buffet fellatio far anticipate\n",
      "Original Review:\n",
      "The Buffet at Bellagio was far from what I anticipated.\n",
      "Probability: [0.33306824 0.66693176]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "give thumb\n",
      "Original Review:\n",
      "I give it 2 thumbs down\n",
      "Probability: [0.34823396 0.65176604]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "service give star\n",
      "Original Review:\n",
      "For service, I give them no stars.\n",
      "Probability: [0.48000825 0.51999175]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "burger aren't good pizza use amaze doughy flavorless\n",
      "Original Review:\n",
      "Now the burgers aren't as good, the pizza which used to be amazing is doughy and flavorless.\n",
      "Probability: [0.32531712 0.67468288]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "tough short flavor !\n",
      "Original Review:\n",
      "very tough and very short on flavor!\n",
      "Probability: [0.4678083 0.5321917]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "attach gas station rarely good sign\n",
      "Original Review:\n",
      "It was attached to a gas station, and that is rarely a good sign.\n",
      "Probability: [0.44316465 0.55683535]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "service fair best\n",
      "Original Review:\n",
      "The service here is fair at best.\n",
      "Probability: [0.29557853 0.70442147]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "must night place\n",
      "Original Review:\n",
      "Must have been an off night at this place.\n",
      "Probability: [0.44257027 0.55742973]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "aren't one make scene restaurant don't get definitely lose love one !\n",
      "Original Review:\n",
      "We aren't ones to make a scene at restaurants but I just don't get it...definitely lost the love after this one!\n",
      "Probability: [0.45649794 0.54350206]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "packed ! !\n",
      "Original Review:\n",
      "It was packed!!\n",
      "Probability: [0.41904993 0.58095007]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "love sushi found kabuki overprice overdid underservices\n",
      "Original Review:\n",
      "I do love sushi, but I found Kabuki to be over-priced, over-hip and under-services.\n",
      "Probability: [0.22537481 0.77462519]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "extremely rude really many restaurant would love dine weekend vega\n",
      "Original Review:\n",
      "He was extremely rude and really, there are so many other restaurants I would love to dine at during a weekend in Vegas.\n",
      "Probability: [0.35667716 0.64332284]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "dress treat rudely !\n",
      "Original Review:\n",
      "I dressed up to be treated so rudely!\n",
      "Probability: [0.44944497 0.55055503]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "ryan's bar definitely one edinburgh establishment won't revisit\n",
      "Original Review:\n",
      "Ryan's Bar is definitely one Edinburgh establishment I won't be revisiting.\n",
      "Probability: [0.4164772 0.5835228]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "sushi strip place go\n",
      "Original Review:\n",
      "For sushi on the Strip, this is the place to go.\n",
      "Probability: [0.50640012 0.49359988]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "oh thing beauty restaurant\n",
      "Original Review:\n",
      "Oh this is such a thing of beauty, this restaurant.\n",
      "Probability: [0.50919616 0.49080384]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "found place accident could not happier\n",
      "Original Review:\n",
      "I found this place by accident and I could not be happier.\n",
      "Probability: [0.71844888 0.28155112]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "one bite hooked\n",
      "Original Review:\n",
      "After one bite, I was hooked.\n",
      "Probability: [0.56473284 0.43526716]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "assure won't disappointed\n",
      "Original Review:\n",
      "I can assure you that you won't be disappointed.\n",
      "Probability: [0.63775017 0.36224983]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not mention combination pear almond bacon big winner !\n",
      "Original Review:\n",
      "Not to mention the combination of pears, almonds and bacon is a big winner!\n",
      "Probability: [0.59353186 0.40646814]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "can't wait go back\n",
      "Original Review:\n",
      "I can't wait to go back.\n",
      "Probability: [0.77780183 0.22219817]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "cant go wrong food\n",
      "Original Review:\n",
      "You cant go wrong with any of the food here.\n",
      "Probability: [0.63792495 0.36207505]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "you've not familiar check\n",
      "Original Review:\n",
      "If you're not familiar, check it out.\n",
      "Probability: [0.71235096 0.28764904]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "deal include tasting drink jeff go beyond expect\n",
      "Original Review:\n",
      "The deal included 5 tastings and 2 drinks, and Jeff went above and beyond what we expected.\n",
      "Probability: [0.58594816 0.41405184]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not expect good !\n",
      "Original Review:\n",
      "I did not expect this to be so good!\n",
      "Probability: [0.59553258 0.40446742]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "never anything complain\n",
      "Original Review:\n",
      "Never had anything to complain about here.\n",
      "Probability: [0.53234873 0.46765127]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "first vega buffet not disappoint\n",
      "Original Review:\n",
      "This was my first and only Vegas buffet and it did not disappoint.\n",
      "Probability: [0.90042801 0.09957199]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "wonton thin not thick chewy almost melt mouth\n",
      "Original Review:\n",
      "The wontons were thin, not thick and chewy, almost melt in your mouth.\n",
      "Probability: [0.59189014 0.40810986]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "not fun experience\n",
      "Original Review:\n",
      "It was just not a fun experience.\n",
      "Probability: [0.68546623 0.31453377]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "om felt like never eat thai food dish\n",
      "Original Review:\n",
      "OMG I felt like I had never eaten Thai food until this dish.\n",
      "Probability: [0.6321722 0.3678278]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "back many time soon\n",
      "Original Review:\n",
      "I will be back many times soon.\n",
      "Probability: [0.58493005 0.41506995]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "make drive way north scottsdale not one bit disappointed !\n",
      "Original Review:\n",
      "We made the drive all the way from North Scottsdale... and I was not one bit disappointed!\n",
      "Probability: [0.94203266 0.05796734]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "won't disappointed\n",
      "Original Review:\n",
      "You won't be disappointed.\n",
      "Probability: [0.774775 0.225225]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "restaurant always full never wait\n",
      "Original Review:\n",
      "Restaurant is always full but never a wait.\n",
      "Probability: [0.63697849 0.36302151]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "point finger item menu order won't disappointed\n",
      "Original Review:\n",
      "Point your finger at any item on the menu, order it and you won't be disappointed.\n",
      "Probability: [0.55738384 0.44261616]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "goat taco didn't skimp meat wow flavor !\n",
      "Original Review:\n",
      "The goat taco didn't skimp on the meat and wow what FLAVOR!\n",
      "Probability: [0.60934363 0.39065637]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "deserves star\n",
      "Original Review:\n",
      "He deserves 5 stars.\n",
      "Probability: [0.51307398 0.48692602]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "lordy khan soi dish not miss curry lover !\n",
      "Original Review:\n",
      "Lordy, the Khao Soi is a dish that is not to be missed for curry lovers!\n",
      "Probability: [0.68043542 0.31956458]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "first time can't wait next\n",
      "Original Review:\n",
      "This was my first time and I can't wait until the next.\n",
      "Probability: [0.82459782 0.17540218]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "don't many word say place everything pretty well\n",
      "Original Review:\n",
      "I don't have very many words to say about this place, but it does everything pretty well.\n",
      "Probability: [0.51956083 0.48043917]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "could eat bruschetta day devine\n",
      "Original Review:\n",
      "I could eat their bruschetta all day it is devine.\n",
      "Probability: [0.65452502 0.34547498]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print(\"Butchered Review:\")\n",
    "    print(reviews_string.split(\"\\n\")[i])\n",
    "    #print('\\n')\n",
    "    print(\"Original Review:\")\n",
    "    print(original_review_string.split(\"\\n\")[i])\n",
    "    #print('\\n')\n",
    "    print(\"Probability:\", probas[i])\n",
    "    print(\"Predicted:\", train_predictions[i])\n",
    "    print(\"Actual:\", y_tr_N[i])\n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "af1f6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_string = \"Plan on ordering from them again and again.\"\n",
    "#preprocess_string(test_string)\n",
    "reviews_string3 = test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "b291df0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan on ordering from them again and again '"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = remove_non_alpha_num(reviews_string3)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "161aec85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan on ordering from them again and again'"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = correct_spelling(reviews_string3)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744bf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456008a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eae76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "7bd75061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan on order from them again and again'"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = lemmatize_words(reviews_string3)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "2b5c2234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan order'"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = remove_stop_words(reviews_string3, stop_words)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
