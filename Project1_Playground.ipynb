{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca65df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_df: (2400, 2)\n",
      "Shape of y_train_df: (2400, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_dir = 'data_reviews'\n",
    "    x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "    y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "    N, n_cols = x_train_df.shape\n",
    "    print(\"Shape of x_train_df: (%d, %d)\" % (N,n_cols))\n",
    "    print(\"Shape of y_train_df: %s\" % str(y_train_df.shape))\n",
    "\n",
    "#     # Print out the first five rows and last five rows\n",
    "#     tr_text_list = x_train_df['text'].values.tolist()\n",
    "#     rows = np.arange(0, 5)\n",
    "#     for row_id in rows:\n",
    "#         text = tr_text_list[row_id]\n",
    "#         print(\"row %5d | y = %d | %s\" % (row_id, y_train_df.values[row_id,0], text))\n",
    "\n",
    "#     print(\"...\")\n",
    "#     rows = np.arange(N - 5, N)\n",
    "#     for row_id in rows:\n",
    "#         text = tr_text_list[row_id]\n",
    "#         print(\"row %5d | y = %d | %s\" % (row_id, y_train_df.values[row_id,0], text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ed141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef01e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps\n",
    "#load data into python\n",
    "x_train_df = pd.read_csv('data_reviews/x_train.csv')\n",
    "tr_list_of_sentences = x_train_df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf9845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the approach from lab\n",
    "def tokenize_text(raw_text):\n",
    "    ''' Transform a plain-text string into a list of tokens\n",
    "    \n",
    "    We assume that *whitespace* divides tokens.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    raw_text : string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_tokens : list of strings\n",
    "        Each element is one token in the provided text\n",
    "    '''\n",
    "    list_of_tokens = raw_text.split() # split method divides on whitespace by default\n",
    "    for pp in range(len(list_of_tokens)):\n",
    "        cur_token = list_of_tokens[pp]\n",
    "        # Remove punctuation\n",
    "        for punc in ['?', '!', '_', '.', ',', '\"', '/']:\n",
    "            cur_token = cur_token.replace(punc, \"\")\n",
    "        # Turn to lower case\n",
    "        clean_token = cur_token.lower()\n",
    "        # Replace the cleaned token into the original list\n",
    "        list_of_tokens[pp] = clean_token\n",
    "    return list_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6db706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102bf98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/liam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/liam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Oh and I forgot to also mention the weird color effect it has on your phone.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "tr_list_of_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2e51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de5d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = {word.replace(\"'\", '') for word in stop_words}\n",
    "toRemove = {'not', 'couldnt', 'shouldnt'}\n",
    "for entry in toRemove:\n",
    "    stop_words.discard(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5f8a5",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c19e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e4641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a780b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code is from the Bag of Words Lab\n",
    "\n",
    "def create_tok_count(list_of_sentences):\n",
    "    tok_count_dict = dict()\n",
    "\n",
    "    for line in list_of_sentences:\n",
    "        tok_list = tokenize_text(line)\n",
    "        for tok in tok_list:\n",
    "            if tok in tok_count_dict:\n",
    "                tok_count_dict[tok] += 1\n",
    "            else:\n",
    "                tok_count_dict[tok] = 1\n",
    "                    \n",
    "    return tok_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd777fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d698750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6fc66f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tok_count_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sorted_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[43mtok_count_dict\u001b[49m, key\u001b[38;5;241m=\u001b[39mtok_count_dict\u001b[38;5;241m.\u001b[39mget, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tok_count_dict' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_tokens = list(sorted(tok_count_dict, key=tok_count_dict.get, reverse=True))\n",
    "# for w in sorted_tokens[:10]:\n",
    "#     print(\"%5d %s\" % (tok_count_dict[w], w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0248bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_tokens[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in sorted_tokens[-10:]:\n",
    "#     print(\"%5d %s\" % (tok_count_dict[w], w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98df791",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#filtering out the 10 most common tokens (since they don't do much to influence the positivity or negativity of a review)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msorted_tokens\u001b[49m[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "#filtering out the 10 most common tokens (since they don't do much to influence the positivity or negativity of a review)\n",
    "sorted_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a81c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_list = sorted_tokens[10:]\n",
    "FREQ_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed8e124b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#need to decide whether or not we want to filter out the tokens that aren't used very much\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vocab_list \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43msorted_tokens\u001b[49m[:] \u001b[38;5;28;01mif\u001b[39;00m tok_count_dict[w] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m FREQ_THRESHOLD]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "#need to decide whether or not we want to filter out the tokens that aren't used very much\n",
    "vocab_list = [w for w in sorted_tokens[:] if tok_count_dict[w] >= FREQ_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15ae9467",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vocab_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vocab_id, tok \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mvocab_list\u001b[49m):\n\u001b[1;32m      3\u001b[0m     vocab_dict[tok] \u001b[38;5;241m=\u001b[39m vocab_id\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_list' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_dict = dict()\n",
    "for vocab_id, tok in enumerate(vocab_list):\n",
    "    vocab_dict[tok] = vocab_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd637a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2173741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_into_feature_vector(text, vocab_dict):\n",
    "    ''' Produce count feature vector for provided text\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    text : string\n",
    "        A string of raw text, representing a single 'review'\n",
    "    vocab_dict : dict with string keys\n",
    "        If token is in vocabulary, will exist as key in the dict\n",
    "        If token is not in vocabulary, will not be in the dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    count_V : 1D numpy array, shape (V,) = (n_vocab,)\n",
    "        Count vector, indicating how often each vocab word\n",
    "        appears in the provided text string\n",
    "    '''\n",
    "    V = len(vocab_dict.keys())\n",
    "    count_V = np.zeros(V)\n",
    "    for tok in tokenize_text(text):\n",
    "        if tok in vocab_dict:\n",
    "            vv = vocab_dict[tok]\n",
    "            count_V[vv] += 1\n",
    "    return count_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee3dc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive words (should produce a few positive entries!)\n",
    "#transform_text_into_feature_vector(\"good great fantastic excellent good\", vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4918bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9a3917ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "585e32e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of reviews\n",
    "N = len(tr_list_of_sentences)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "37eba9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of vocabulary\n",
    "V = len(vocab_list)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "139540bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc3206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9f00d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_N = np.hstack([np.zeros(N//2), np.ones(N//2)])\n",
    "x_tr_NV = np.zeros((N, V))\n",
    "for nn, raw_text_line in enumerate(tr_list_of_sentences):\n",
    "    x_tr_NV[nn] = transform_text_into_feature_vector(raw_text_line, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdefe5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7e6d2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26046d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7f3bdc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "55abedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.linear_model\n",
    "# import sklearn.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "64594e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just pick reasonable choices for quick demo\n",
    "# We may see a \"ConvergenceWarning\". That's fine for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b58580d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(x_tr_NV, y_tr_N)\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ed89fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "41cfe93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeRand = Pipeline([['clf', LogisticRegression(penalty = 'l2',\n",
    "#                                                 max_iter=400)]\n",
    "#                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "44dcff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LogisticRegression(solver='lbfgs')\n",
    "SEED = 2\n",
    "FOLDS = 15\n",
    "\n",
    "#hyperparameter optimization\n",
    "# C_grid = loguniform(1e-3, 1e3)\n",
    "\n",
    "# tolerance = [1e-1,1e-2,1e-3,1e-4,1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "521efd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cRange = loguniform(1e-3, 1e3)\n",
    "tol = [1e-1,1e-2,1e-3,1e-4,1e-5]\n",
    "SEED = 1\n",
    "#max_iter_values = [100, 200, 300, 400, 500]\n",
    "param_rand = {\n",
    "    'clf__C': cRange,\n",
    "    'clf__tol': tol,\n",
    "    'clf__fit_intercept': [True, False]\n",
    "    \n",
    "    #clf__max_iter': max_iter_values\n",
    "    \n",
    "}\n",
    "\n",
    "# pipeRand = Pipeline([['scaler', StandardScaler()],\n",
    "#                      ['clf', LogisticRegression(penalty = 'l2',\n",
    "#                                                 max_iter=300)]\n",
    "#                     ])\n",
    "pipeRand = Pipeline([['clf', sklearn.linear_model.LogisticRegression(penalty = 'l2',\n",
    "                                                max_iter=400)]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "586d6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rand = {\n",
    "    'clf__C': cRange,\n",
    "    'clf__tol': tol,\n",
    "    'clf__fit_intercept': [True, False]\n",
    "    \n",
    "    #clf__max_iter': max_iter_values\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b6cc0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {\n",
    "    'C': C_grid,\n",
    "    'tol': tolerance,\n",
    "    'fit_intercept': [True, False]\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dbb4b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_search = RandomizedSearchCV(\n",
    "    estimator = pipeRand,\n",
    "    param_distributions = param_rand,\n",
    "    cv = FOLDS,\n",
    "    scoring = 'roc_auc',\n",
    "    random_state = SEED,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c9f4a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tr_NV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx_tr_NV\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_tr_NV' is not defined"
     ]
    }
   ],
   "source": [
    "x_tr_NV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b11bde94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=15,\n",
       "                   estimator=Pipeline(steps=[[&#x27;clf&#x27;,\n",
       "                                              LogisticRegression(max_iter=400)]]),\n",
       "                   param_distributions={&#x27;clf__C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fc73c4e8e50&gt;,\n",
       "                                        &#x27;clf__fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;clf__tol&#x27;: [0.1, 0.01, 0.001, 0.0001,\n",
       "                                                     1e-05]},\n",
       "                   random_state=1, scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=15,\n",
       "                   estimator=Pipeline(steps=[[&#x27;clf&#x27;,\n",
       "                                              LogisticRegression(max_iter=400)]]),\n",
       "                   param_distributions={&#x27;clf__C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fc73c4e8e50&gt;,\n",
       "                                        &#x27;clf__fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;clf__tol&#x27;: [0.1, 0.01, 0.001, 0.0001,\n",
       "                                                     1e-05]},\n",
       "                   random_state=1, scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[[&#x27;clf&#x27;, LogisticRegression(max_iter=400)]])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=400)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=15,\n",
       "                   estimator=Pipeline(steps=[['clf',\n",
       "                                              LogisticRegression(max_iter=400)]]),\n",
       "                   param_distributions={'clf__C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fc73c4e8e50>,\n",
       "                                        'clf__fit_intercept': [True, False],\n",
       "                                        'clf__tol': [0.1, 0.01, 0.001, 0.0001,\n",
       "                                                     1e-05]},\n",
       "                   random_state=1, scoring='roc_auc')"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_search.fit(x_tr_NV, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4d70904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.32746665712253886, 'clf__fit_intercept': True, 'clf__tol': 1e-05}\n",
      "Best score: 0.8917187500000001\n",
      "Best pipeline: Pipeline(steps=[['clf',\n",
      "                 LogisticRegression(C=0.32746665712253886, max_iter=400,\n",
      "                                    tol=1e-05)]])\n",
      "Index of best pipeline: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__fit_intercept</th>\n",
       "      <th>param_clf__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058289</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.317784</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 0.3177840006884069, 'clf__fit_inter...</td>\n",
       "      <td>0.863438</td>\n",
       "      <td>0.862109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898125</td>\n",
       "      <td>0.918047</td>\n",
       "      <td>0.896719</td>\n",
       "      <td>0.895313</td>\n",
       "      <td>0.896406</td>\n",
       "      <td>0.874844</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.027208</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 0.001001581395585897, 'clf__fit_int...</td>\n",
       "      <td>0.774531</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813906</td>\n",
       "      <td>0.826797</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.836875</td>\n",
       "      <td>0.816250</td>\n",
       "      <td>0.798750</td>\n",
       "      <td>0.879062</td>\n",
       "      <td>0.808417</td>\n",
       "      <td>0.035827</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035615</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'clf__C': 0.0035812246787002297, 'clf__fit_in...</td>\n",
       "      <td>0.780937</td>\n",
       "      <td>0.781328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821094</td>\n",
       "      <td>0.835078</td>\n",
       "      <td>0.802813</td>\n",
       "      <td>0.838594</td>\n",
       "      <td>0.820937</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.814333</td>\n",
       "      <td>0.034956</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068288</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.240218</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'clf__C': 0.24021761202431602, 'clf__fit_inte...</td>\n",
       "      <td>0.859219</td>\n",
       "      <td>0.859297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894375</td>\n",
       "      <td>0.915234</td>\n",
       "      <td>0.891250</td>\n",
       "      <td>0.894062</td>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.870625</td>\n",
       "      <td>0.940156</td>\n",
       "      <td>0.888083</td>\n",
       "      <td>0.027263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070809</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.327467</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'clf__C': 0.32746665712253886, 'clf__fit_inte...</td>\n",
       "      <td>0.863594</td>\n",
       "      <td>0.861953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899219</td>\n",
       "      <td>0.918516</td>\n",
       "      <td>0.897031</td>\n",
       "      <td>0.895469</td>\n",
       "      <td>0.897344</td>\n",
       "      <td>0.875313</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.891719</td>\n",
       "      <td>0.027114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033966</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'clf__C': 0.01685440782816938, 'clf__fit_inte...</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.802422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844219</td>\n",
       "      <td>0.864453</td>\n",
       "      <td>0.816719</td>\n",
       "      <td>0.851094</td>\n",
       "      <td>0.840469</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.903438</td>\n",
       "      <td>0.836375</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026191</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'clf__C': 0.0014599082378876644, 'clf__fit_in...</td>\n",
       "      <td>0.775312</td>\n",
       "      <td>0.776953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815781</td>\n",
       "      <td>0.828672</td>\n",
       "      <td>0.800156</td>\n",
       "      <td>0.836875</td>\n",
       "      <td>0.816875</td>\n",
       "      <td>0.798750</td>\n",
       "      <td>0.880625</td>\n",
       "      <td>0.809688</td>\n",
       "      <td>0.035670</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.049153</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.319028</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 0.3190280094957601, 'clf__fit_inter...</td>\n",
       "      <td>0.859063</td>\n",
       "      <td>0.858828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898750</td>\n",
       "      <td>0.919453</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.897031</td>\n",
       "      <td>0.898594</td>\n",
       "      <td>0.878438</td>\n",
       "      <td>0.943906</td>\n",
       "      <td>0.891167</td>\n",
       "      <td>0.027408</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.027504</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 0.006955392321661605, 'clf__fit_int...</td>\n",
       "      <td>0.788594</td>\n",
       "      <td>0.786797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827969</td>\n",
       "      <td>0.845547</td>\n",
       "      <td>0.807656</td>\n",
       "      <td>0.842656</td>\n",
       "      <td>0.827969</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.891406</td>\n",
       "      <td>0.821354</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.265443</td>\n",
       "      <td>0.012437</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>645.014465</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 645.0144652189368, 'clf__fit_interc...</td>\n",
       "      <td>0.802031</td>\n",
       "      <td>0.793516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836250</td>\n",
       "      <td>0.873828</td>\n",
       "      <td>0.796406</td>\n",
       "      <td>0.841094</td>\n",
       "      <td>0.856094</td>\n",
       "      <td>0.809063</td>\n",
       "      <td>0.855156</td>\n",
       "      <td>0.839365</td>\n",
       "      <td>0.033740</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
       "0       0.058289      0.024613         0.001944        0.000280     0.317784   \n",
       "1       0.021908      0.002570         0.001854        0.000227     0.001002   \n",
       "2       0.035615      0.003918         0.002205        0.000474     0.003581   \n",
       "3       0.068288      0.007203         0.002214        0.000404     0.240218   \n",
       "4       0.070809      0.006949         0.001982        0.000362     0.327467   \n",
       "5       0.033966      0.002746         0.002010        0.000306     0.016854   \n",
       "6       0.026191      0.002014         0.001962        0.000255      0.00146   \n",
       "7       0.049153      0.004033         0.001986        0.000413     0.319028   \n",
       "8       0.027504      0.001840         0.001884        0.000381     0.006955   \n",
       "9       0.265443      0.012437         0.002050        0.000315   645.014465   \n",
       "\n",
       "  param_clf__fit_intercept param_clf__tol  \\\n",
       "0                     True            0.1   \n",
       "1                    False            0.1   \n",
       "2                     True        0.00001   \n",
       "3                     True        0.00001   \n",
       "4                     True        0.00001   \n",
       "5                     True        0.00001   \n",
       "6                     True        0.00001   \n",
       "7                    False           0.01   \n",
       "8                     True           0.01   \n",
       "9                    False           0.01   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__C': 0.3177840006884069, 'clf__fit_inter...           0.863438   \n",
       "1  {'clf__C': 0.001001581395585897, 'clf__fit_int...           0.774531   \n",
       "2  {'clf__C': 0.0035812246787002297, 'clf__fit_in...           0.780937   \n",
       "3  {'clf__C': 0.24021761202431602, 'clf__fit_inte...           0.859219   \n",
       "4  {'clf__C': 0.32746665712253886, 'clf__fit_inte...           0.863594   \n",
       "5  {'clf__C': 0.01685440782816938, 'clf__fit_inte...           0.805625   \n",
       "6  {'clf__C': 0.0014599082378876644, 'clf__fit_in...           0.775312   \n",
       "7  {'clf__C': 0.3190280094957601, 'clf__fit_inter...           0.859063   \n",
       "8  {'clf__C': 0.006955392321661605, 'clf__fit_int...           0.788594   \n",
       "9  {'clf__C': 645.0144652189368, 'clf__fit_interc...           0.802031   \n",
       "\n",
       "   split1_test_score  ...  split8_test_score  split9_test_score  \\\n",
       "0           0.862109  ...           0.898125           0.918047   \n",
       "1           0.775391  ...           0.813906           0.826797   \n",
       "2           0.781328  ...           0.821094           0.835078   \n",
       "3           0.859297  ...           0.894375           0.915234   \n",
       "4           0.861953  ...           0.899219           0.918516   \n",
       "5           0.802422  ...           0.844219           0.864453   \n",
       "6           0.776953  ...           0.815781           0.828672   \n",
       "7           0.858828  ...           0.898750           0.919453   \n",
       "8           0.786797  ...           0.827969           0.845547   \n",
       "9           0.793516  ...           0.836250           0.873828   \n",
       "\n",
       "   split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0            0.896719            0.895313            0.896406   \n",
       "1            0.800000            0.836875            0.816250   \n",
       "2            0.802813            0.838594            0.820937   \n",
       "3            0.891250            0.894062            0.892188   \n",
       "4            0.897031            0.895469            0.897344   \n",
       "5            0.816719            0.851094            0.840469   \n",
       "6            0.800156            0.836875            0.816875   \n",
       "7            0.900156            0.897031            0.898594   \n",
       "8            0.807656            0.842656            0.827969   \n",
       "9            0.796406            0.841094            0.856094   \n",
       "\n",
       "   split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.874844            0.943750         0.891333        0.027208   \n",
       "1            0.798750            0.879062         0.808417        0.035827   \n",
       "2            0.800781            0.884375         0.814333        0.034956   \n",
       "3            0.870625            0.940156         0.888083        0.027263   \n",
       "4            0.875313            0.943750         0.891719        0.027114   \n",
       "5            0.815000            0.903438         0.836375        0.032263   \n",
       "6            0.798750            0.880625         0.809688        0.035670   \n",
       "7            0.878438            0.943906         0.891167        0.027408   \n",
       "8            0.805000            0.891406         0.821354        0.034286   \n",
       "9            0.809063            0.855156         0.839365        0.033740   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1               10  \n",
       "2                8  \n",
       "3                4  \n",
       "4                1  \n",
       "5                6  \n",
       "6                9  \n",
       "7                3  \n",
       "8                7  \n",
       "9                5  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best params:', curr_search.best_params_)\n",
    "print('Best score:', curr_search.best_score_)\n",
    "print('Best pipeline:', curr_search.best_estimator_)\n",
    "print('Index of best pipeline:', curr_search.best_index_)\n",
    "results=pd.DataFrame(curr_search.cv_results_)\n",
    "results #see results of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4e8eef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into 5 folds\n",
    "#searching for a variety of hyperparameter configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790352f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f626d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449960b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3839c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c039f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_valid_err_list\n",
    "# idx = np.argsort(cv_valid_err_list)[:1]\n",
    "# C_grid[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d13b16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf2 = sklearn.linear_model.LogisticRegression(C=C_grid[idx][0], solver='lbfgs')\n",
    "# tr_error_K, valid_error_K = train_models_and_calc_scores_for_n_fold_cv(clf2, x_tr_NV, y_tr_N, FOLDS, SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8f4cd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to split up the data into 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0853b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "dedde0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = sklearn.linear_model.LogisticRegression(\n",
    "#     C=1000.0, max_iter=20)\n",
    "\n",
    "# clf.fit(x_tr_NV, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "35aae0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat_tr_N = clf.predict(x_tr_NV)\n",
    "# acc = np.mean(y_tr_N == yhat_tr_N)\n",
    "\n",
    "# print(\"Training accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ab08092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat_tr_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9e31e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_V = clf.coef_[0]\n",
    "# sorted_tok_ids_V = np.argsort(weights_V)\n",
    "\n",
    "# for vv in sorted_tok_ids_V:\n",
    "#     print(\"% 7.3f %s\" % (weights_V[vv], vocab_list[vv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f3e84244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_V = transform_text_into_feature_vector(\"Not worth it.\", vocab_dict)\n",
    "# clf2.predict(x_V.reshape((1,V)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d7e12db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_V = transform_text_into_feature_vector(\"This is terrible and bad and horrible.\", vocab_dict)\n",
    "# clf2.predict(x_V.reshape((1,V)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5601a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_V = transform_text_into_feature_vector(\"This is amazing and I love it and it is wonderful.\", vocab_dict)\n",
    "# clf2.predict(x_V.reshape((1,V)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b60b1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_V = transform_text_into_feature_vector(\"This is not worth it at all.\", vocab_dict)\n",
    "# clf2.predict(x_V.reshape((1,V)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "485112c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "29e38921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a leaderboard score:\n",
    "x_test_df = pd.read_csv('data_reviews/x_test.csv')\n",
    "test_list_of_sentences = x_test_df['text'].values.tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c3ce18b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>It only recognizes the Phone as its storage de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Disappointing accessory from a good manufacturer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>The one big drawback of the MP3 player is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>This particular model would not work with my M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>If the two were seperated by a mere 5+ ft I st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Everything was fresh and delicious!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>yelp</td>\n",
       "      <td>- Really, really good rice, all the time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Pretty awesome place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The staff are great, the ambiance is great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The patio seating was very comfortable.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    website_name                                               text\n",
       "0         amazon  It only recognizes the Phone as its storage de...\n",
       "1         amazon  Disappointing accessory from a good manufacturer.\n",
       "2         amazon  The one big drawback of the MP3 player is that...\n",
       "3         amazon  This particular model would not work with my M...\n",
       "4         amazon  If the two were seperated by a mere 5+ ft I st...\n",
       "..           ...                                                ...\n",
       "595         yelp                Everything was fresh and delicious!\n",
       "596         yelp          - Really, really good rice, all the time.\n",
       "597         yelp                              Pretty awesome place.\n",
       "598         yelp        The staff are great, the ambiance is great.\n",
       "599         yelp            The patio seating was very comfortable.\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "11030fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "84ee772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in test_list_of_sentences:\n",
    "    \n",
    "    new_list.append(tokenize_text(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ad684f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_RawString = x_test_df['text'].str.cat(sep='\\n')\n",
    "# x_test_RawString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078c1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a6665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6c362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ddcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fab3f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = len(new_list)\n",
    "y_tr_Z = np.hstack([np.zeros(Z//2), np.ones(Z//2)])\n",
    "x_tr_ZV = np.zeros((Z, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "43063379",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn2, raw_text_line2 in enumerate(test_list_of_sentences):\n",
    "    x_tr_ZV[nn2] = transform_text_into_feature_vector(raw_text_line2, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bafd1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_N = curr_search.predict_proba(x_tr_ZV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "859d702c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test_N[:, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "34306223",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"yproba1_test.txt\", yhat_test_N[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1aa80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the results from our first couple models have been very poor (2nd worst in the class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ff510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5afc8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2e84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "def determine_sentiment(word):\n",
    "    afinn = Afinn()\n",
    "    score = afinn.score(word)\n",
    "    \n",
    "    if score > 0:\n",
    "        return 1  # Positive sentiment\n",
    "    elif score < 0:\n",
    "        return -1  # Negative sentiment\n",
    "    else:\n",
    "        return 0  # Neutral/Indeterminate sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af483c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "word = \"mother\"\n",
    "result = determine_sentiment(word)\n",
    "print(result)  # 1 for positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5fdec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
