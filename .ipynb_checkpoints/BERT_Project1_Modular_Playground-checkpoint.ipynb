{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e42ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     data_dir = 'data_reviews'\n",
    "#     x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "#     y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b7330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee721f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interesting model stuff\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20902d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.read_csv('data_reviews/y_train.csv')\n",
    "y_tr_N = y_train_df.is_positive_sentiment.values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a8dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265ef948",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_embeddings = np.load('data_reviews/x_train_BERT_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322497c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_embeddings = np.load('data_reviews/x_test_BERT_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31df460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928fd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a53a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(\"i like to run\", return_tensors=\"pt\")\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09942519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_bert_embedding(sentence_list, pooling_strategy='cls'):\n",
    "#     embedding_list = []\n",
    "#     for nn, sentence in enumerate(sentence_list):\n",
    "#         if (nn%100==0)&(nn>0):\n",
    "#             print('Done with %d sentences'%nn)\n",
    "        \n",
    "#         # Tokenize the sentence and get the output from BERT\n",
    "#         inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "#         # Take the embeddings from the last hidden state (optionally, one can use pooling techniques for different representations)\n",
    "#         # Here, we take the [CLS] token representation as the sentence embedding\n",
    "#         last_hidden_states = outputs.last_hidden_state[0]\n",
    "        \n",
    "#         # Pooling strategies\n",
    "#         if pooling_strategy == \"cls\":\n",
    "#             sentence_embedding = last_hidden_states[0]\n",
    "#         elif pooling_strategy == \"mean\":\n",
    "#             sentence_embedding = torch.mean(last_hidden_states, dim=0)\n",
    "#         elif pooling_strategy == \"max\":\n",
    "#             sentence_embedding, _ = torch.max(last_hidden_states, dim=0)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown pooling strategy: {pooling_strategy}\")\n",
    "        \n",
    "#         embedding_list.append(sentence_embedding)\n",
    "#     return torch.stack(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce36e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_df = pd.read_csv('data_reviews/x_train.csv')\n",
    "# x_test_df = pd.read_csv('data_reviews/x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e480c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #load data into python\n",
    "# # x_train_df = pd.read_csv('data_reviews/x_train.csv')\n",
    "# # #concatenating review to make string processing easier\n",
    "# tr_list_of_sentences = x_train_df['text'].str.cat(sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "466afc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_text_list = x_train_df['text'].values.tolist()\n",
    "# te_text_list = x_test_df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb98de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for train sequences...\n",
      "Done with 100 sentences\n",
      "Done with 200 sentences\n",
      "Done with 300 sentences\n",
      "Done with 400 sentences\n",
      "Done with 500 sentences\n",
      "Done with 600 sentences\n",
      "Done with 700 sentences\n",
      "Done with 800 sentences\n",
      "Done with 900 sentences\n",
      "Done with 1000 sentences\n",
      "Done with 1100 sentences\n",
      "Done with 1200 sentences\n",
      "Done with 1300 sentences\n",
      "Done with 1400 sentences\n",
      "Done with 1500 sentences\n",
      "Done with 1600 sentences\n",
      "Done with 1700 sentences\n",
      "Done with 1800 sentences\n",
      "Done with 1900 sentences\n",
      "Done with 2000 sentences\n",
      "Done with 2100 sentences\n",
      "Done with 2200 sentences\n",
      "Done with 2300 sentences\n",
      "Generating embeddings for test sequences...\n",
      "Done with 100 sentences\n",
      "Done with 200 sentences\n",
      "Done with 300 sentences\n",
      "Done with 400 sentences\n",
      "Done with 500 sentences\n"
     ]
    }
   ],
   "source": [
    "# print('Generating embeddings for train sequences...')\n",
    "# tr_embedding = get_bert_embedding(tr_text_list)\n",
    "\n",
    "# print('Generating embeddings for test sequences...')\n",
    "# te_embedding = get_bert_embedding(te_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58b0a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_embeddings = tr_embedding\n",
    "#x_test_embeddings = te_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32256f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2333,  0.0163, -0.2490,  ..., -0.2287,  0.2553,  0.4603],\n",
       "        [ 0.1105, -0.2516,  0.0978,  ..., -0.0547,  0.2738,  0.3987],\n",
       "        [-0.3586,  0.2972, -0.1850,  ..., -0.2115,  0.2751,  0.0507],\n",
       "        ...,\n",
       "        [-0.0907,  0.1405,  0.0576,  ..., -0.4601,  0.0022,  0.4991],\n",
       "        [ 0.0700, -0.3029, -0.2434,  ..., -0.0634,  0.3375,  0.2220],\n",
       "        [ 0.0030,  0.2055, -0.1326,  ..., -0.4048,  0.2341,  0.3274]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719381bf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03414361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_tuple = (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81e99d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_tuple = (1, 3)\n",
    "# vectorizer = CountVectorizer(ngram_range = ngram_tuple)\n",
    "# X = vectorizer.fit_transform(reviews_string.split(\"\\n\"))\n",
    "# x_prepared_NV = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5705801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23330952,  0.01625735, -0.24896072, ..., -0.22867514,\n",
       "         0.25533253,  0.4602657 ],\n",
       "       [ 0.11047481, -0.25156993,  0.09777027, ..., -0.05472409,\n",
       "         0.27376053,  0.39873978],\n",
       "       [-0.3585949 ,  0.29717323, -0.18498825, ..., -0.2114795 ,\n",
       "         0.27509874,  0.05072442],\n",
       "       ...,\n",
       "       [-0.09073913,  0.14054628,  0.05764995, ..., -0.46014374,\n",
       "         0.00215817,  0.49907732],\n",
       "       [ 0.06995992, -0.30289024, -0.24343982, ..., -0.06344175,\n",
       "         0.33752707,  0.2219671 ],\n",
       "       [ 0.00303933,  0.20548101, -0.1325533 , ..., -0.40481687,\n",
       "         0.23412326,  0.32739362]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d073d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_prepared_NV = x_train_embeddings.detach().cpu().numpy()\n",
    "# #x_test_embeddings = te_embedding.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b160cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prepared_NV = x_train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a85fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d365119",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c0bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "SEED = 2\n",
    "FOLDS = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe8e178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cRange = loguniform(1e-3, 1e3)\n",
    "tol = [0, 1e-1,1e-2,1e-3,1e-4,1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "135dd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver 'lbfgs' does not support an l1 penalty\n",
    "distributions = {\n",
    "    'C': cRange,\n",
    "    'penalty': ['l2'],\n",
    "    'tol': tol,\n",
    "    'fit_intercept': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b33aa2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_search = RandomizedSearchCV(\n",
    "    estimator = model,\n",
    "    param_distributions = distributions,\n",
    "    scoring = 'roc_auc',\n",
    "    return_train_score = True,\n",
    "    cv = FOLDS,\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45765969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebface95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liam/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=15, estimator=LogisticRegression(max_iter=300),\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fce57e63df0&gt;,\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0, 0.1, 0.01, 0.001, 0.0001,\n",
       "                                                1e-05]},\n",
       "                   return_train_score=True, scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=15, estimator=LogisticRegression(max_iter=300),\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fce57e63df0&gt;,\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0, 0.1, 0.01, 0.001, 0.0001,\n",
       "                                                1e-05]},\n",
       "                   return_train_score=True, scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=15, estimator=LogisticRegression(max_iter=300),\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fce57e63df0>,\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'penalty': ['l2'],\n",
       "                                        'tol': [0, 0.1, 0.01, 0.001, 0.0001,\n",
       "                                                1e-05]},\n",
       "                   return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_search.fit(x_prepared_NV, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1bb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ccc43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best score:\n",
    "#ngrams: \n",
    "# (1, 2) 0.90636\n",
    "# (2, 2) 0.74 (absolute garbage, clearly I need the 1)\n",
    "# (1, 3) 0.90410 (I am thinking that anything beyond 2 n grams isn't super helpful)\n",
    "\n",
    "#trying using bert data\n",
    "# bruh. no n grams first try 0.968. what the fuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb86e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.021600633430834522, 'fit_intercept': True, 'penalty': 'l2', 'tol': 0}\n",
      "Best score: 0.9678125000000002\n",
      "Best pipeline: LogisticRegression(C=0.021600633430834522, max_iter=300, tol=0)\n",
      "Index of best pipeline: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301733</td>\n",
       "      <td>0.060691</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.32489</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.3248900296836622, 'fit_intercept': Tru...</td>\n",
       "      <td>0.960156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991063</td>\n",
       "      <td>0.991401</td>\n",
       "      <td>0.990643</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.991330</td>\n",
       "      <td>0.991224</td>\n",
       "      <td>0.990379</td>\n",
       "      <td>0.990506</td>\n",
       "      <td>0.991042</td>\n",
       "      <td>3.533685e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300979</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>231.80676</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 231.80676004364742, 'fit_intercept': Fal...</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.426834</td>\n",
       "      <td>0.059910</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>36.511612</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 36.511611814192115, 'fit_intercept': Fal...</td>\n",
       "      <td>0.948438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.866584e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.478001</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>35.073978</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'C': 35.07397773111398, 'fit_intercept': True...</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412969</td>\n",
       "      <td>0.025858</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>3.099467</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 3.099467064353855, 'fit_intercept': Fals...</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.999424</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>6.147646e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.459316</td>\n",
       "      <td>0.023201</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>475.865435</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 475.86543510981176, 'fit_intercept': Fal...</td>\n",
       "      <td>0.947656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.099436</td>\n",
       "      <td>0.028241</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.021600633430834522, 'fit_intercept': T...</td>\n",
       "      <td>0.956875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977079</td>\n",
       "      <td>0.977223</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>0.976855</td>\n",
       "      <td>0.977460</td>\n",
       "      <td>0.977875</td>\n",
       "      <td>0.975660</td>\n",
       "      <td>0.976283</td>\n",
       "      <td>0.977026</td>\n",
       "      <td>6.657271e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.063755</td>\n",
       "      <td>0.017689</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.02071</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.020709549790716646, 'fit_intercept': T...</td>\n",
       "      <td>0.956719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976857</td>\n",
       "      <td>0.977024</td>\n",
       "      <td>0.975902</td>\n",
       "      <td>0.976680</td>\n",
       "      <td>0.977227</td>\n",
       "      <td>0.977671</td>\n",
       "      <td>0.975441</td>\n",
       "      <td>0.976073</td>\n",
       "      <td>0.976822</td>\n",
       "      <td>6.639609e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.046902</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.0015650269828156966, 'fit_intercept': ...</td>\n",
       "      <td>0.947812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963165</td>\n",
       "      <td>0.962683</td>\n",
       "      <td>0.961413</td>\n",
       "      <td>0.962842</td>\n",
       "      <td>0.963011</td>\n",
       "      <td>0.964412</td>\n",
       "      <td>0.960863</td>\n",
       "      <td>0.961857</td>\n",
       "      <td>0.962747</td>\n",
       "      <td>9.815405e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.436370</td>\n",
       "      <td>0.042806</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>2.479241</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 2.4792407327886954, 'fit_intercept': Fal...</td>\n",
       "      <td>0.955313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>0.999264</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>0.999182</td>\n",
       "      <td>0.999126</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>8.096089e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time     param_C  \\\n",
       "0       0.301733      0.060691         0.002280        0.000513     0.32489   \n",
       "1       0.300979      0.049800         0.002552        0.000468   231.80676   \n",
       "2       0.426834      0.059910         0.002761        0.000713   36.511612   \n",
       "3       0.478001      0.022083         0.003132        0.000536   35.073978   \n",
       "4       0.412969      0.025858         0.002696        0.000501    3.099467   \n",
       "5       0.459316      0.023201         0.002936        0.000413  475.865435   \n",
       "6       0.099436      0.028241         0.002412        0.000369    0.021601   \n",
       "7       0.063755      0.017689         0.002317        0.000326     0.02071   \n",
       "8       0.046902      0.004852         0.002466        0.000519    0.001565   \n",
       "9       0.436370      0.042806         0.002566        0.000358    2.479241   \n",
       "\n",
       "  param_fit_intercept param_penalty param_tol  \\\n",
       "0                True            l2         0   \n",
       "1               False            l2       0.1   \n",
       "2               False            l2       0.1   \n",
       "3                True            l2   0.00001   \n",
       "4               False            l2      0.01   \n",
       "5               False            l2    0.0001   \n",
       "6                True            l2         0   \n",
       "7                True            l2       0.1   \n",
       "8                True            l2      0.01   \n",
       "9               False            l2         0   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "0  {'C': 0.3248900296836622, 'fit_intercept': Tru...           0.960156  ...   \n",
       "1  {'C': 231.80676004364742, 'fit_intercept': Fal...           0.947500  ...   \n",
       "2  {'C': 36.511611814192115, 'fit_intercept': Fal...           0.948438  ...   \n",
       "3  {'C': 35.07397773111398, 'fit_intercept': True...           0.948750  ...   \n",
       "4  {'C': 3.099467064353855, 'fit_intercept': Fals...           0.953750  ...   \n",
       "5  {'C': 475.86543510981176, 'fit_intercept': Fal...           0.947656  ...   \n",
       "6  {'C': 0.021600633430834522, 'fit_intercept': T...           0.956875  ...   \n",
       "7  {'C': 0.020709549790716646, 'fit_intercept': T...           0.956719  ...   \n",
       "8  {'C': 0.0015650269828156966, 'fit_intercept': ...           0.947812  ...   \n",
       "9  {'C': 2.4792407327886954, 'fit_intercept': Fal...           0.955313  ...   \n",
       "\n",
       "   split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0            0.991063            0.991401            0.990643   \n",
       "1            1.000000            1.000000            1.000000   \n",
       "2            1.000000            1.000000            1.000000   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "4            0.999468            0.999588            0.999428   \n",
       "5            1.000000            1.000000            1.000000   \n",
       "6            0.977079            0.977223            0.976079   \n",
       "7            0.976857            0.977024            0.975902   \n",
       "8            0.963165            0.962683            0.961413   \n",
       "9            0.999129            0.999264            0.999050   \n",
       "\n",
       "   split10_train_score  split11_train_score  split12_train_score  \\\n",
       "0             0.990769             0.991330             0.991224   \n",
       "1             1.000000             1.000000             1.000000   \n",
       "2             1.000000             1.000000             1.000000   \n",
       "3             1.000000             1.000000             1.000000   \n",
       "4             0.999474             0.999501             0.999479   \n",
       "5             1.000000             1.000000             1.000000   \n",
       "6             0.976855             0.977460             0.977875   \n",
       "7             0.976680             0.977227             0.977671   \n",
       "8             0.962842             0.963011             0.964412   \n",
       "9             0.999130             0.999182             0.999126   \n",
       "\n",
       "   split13_train_score  split14_train_score  mean_train_score  std_train_score  \n",
       "0             0.990379             0.990506          0.991042     3.533685e-04  \n",
       "1             1.000000             1.000000          1.000000     0.000000e+00  \n",
       "2             1.000000             1.000000          1.000000     2.866584e-17  \n",
       "3             1.000000             1.000000          1.000000     0.000000e+00  \n",
       "4             0.999318             0.999424          0.999473     6.147646e-05  \n",
       "5             1.000000             1.000000          1.000000     0.000000e+00  \n",
       "6             0.975660             0.976283          0.977026     6.657271e-04  \n",
       "7             0.975441             0.976073          0.976822     6.639609e-04  \n",
       "8             0.960863             0.961857          0.962747     9.815405e-04  \n",
       "9             0.998941             0.999055          0.999130     8.096089e-05  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best params:', curr_search.best_params_)\n",
    "print('Best score:', curr_search.best_score_)\n",
    "print('Best pipeline:', curr_search.best_estimator_)\n",
    "print('Index of best pipeline:', curr_search.best_index_)\n",
    "results=pd.DataFrame(curr_search.cv_results_)\n",
    "results #see results of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fa529df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_params = {\n",
    "    'C': 0.13988962084008974, \n",
    "    'fit_intercept': False, \n",
    "    'penalty': 'l2', \n",
    "    'tol': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21c9358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = sklearn.linear_model.LogisticRegression(C=0.13988962084008974, fit_intercept=False, solver='lbfgs', penalty='l2', tol=0.1, max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f968c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64abf8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.13988962084008974, fit_intercept=False, max_iter=300,\n",
       "                   tol=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.13988962084008974, fit_intercept=False, max_iter=300,\n",
       "                   tol=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.13988962084008974, fit_intercept=False, max_iter=300,\n",
       "                   tol=0.1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(x_prepared_NV, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e384f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_N = curr_search.predict_proba(x_test_embeddings)\n",
    "np.savetxt(\"yproba1_test.txt\", yhat_test_N[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43474a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "ecec203e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['param_C'], results['mean_test_score'], 'ro', label='mean_test_score on validation set')\n",
    "# plt.plot(np.log10(C_grid), va_bce_list, 'rs-', label='valid BCE')\n",
    "\n",
    "# plt.plot(np.log10(C_grid), tr_err_list, 'b:', label='train err')\n",
    "# plt.plot(np.log10(C_grid), va_err_list, 'r:', label='valid err')\n",
    "\n",
    "plt.ylabel('error')\n",
    "plt.xlabel(\"$\\log_{10} C$\");\n",
    "plt.legend(bbox_to_anchor=(1.5, 0.5)) # make legend outside plot\n",
    "plt.ylim([0.8, 1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17bfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b8352f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c2e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3fc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6d33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "435f5638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "train_predictions = curr_search.predict(x_prepared_NV)\n",
    "probas = curr_search.predict_proba(x_prepared_NV)\n",
    "b = ~np.equal(train_predictions, y_tr_N)\n",
    "indices = np.flatnonzero(b)\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3ae8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f951080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efacc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok... so it is only getting 4 wrong! This seems really good... not sure how I'm going to improve this\n",
    "reviews_string = tr_list_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de07883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Butchered Review:\n",
      "I really wanted the Plantronics 510 to be the right one, but it has too many issues for me.The good\n",
      "Original Review:\n",
      "I really wanted the Plantronics 510 to be the right one, but it has too many issues for me.The good\n",
      "Probability: [0.29605281 0.70394719]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Excellent starter wireless headset.\n",
      "Original Review:\n",
      "Excellent starter wireless headset.\n",
      "Probability: [0.01422514 0.98577486]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "BT50 battery junk!.\n",
      "Original Review:\n",
      "BT50 battery junk!.\n",
      "Probability: [0.48538589 0.51461411]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Still Waiting...... I'm sure this item would work well.. if I ever recieve it!\n",
      "Original Review:\n",
      "Still Waiting...... I'm sure this item would work well.. if I ever recieve it!\n",
      "Probability: [0.16853193 0.83146807]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Think it over when you plan to own this one!This sure is the last MOTO phone for me!\n",
      "Original Review:\n",
      "Think it over when you plan to own this one!This sure is the last MOTO phone for me!\n",
      "Probability: [0.1957382 0.8042618]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "We are sending it back.\n",
      "Original Review:\n",
      "We are sending it back.\n",
      "Probability: [0.30109354 0.69890646]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I'll be looking for a new earpiece.\n",
      "Original Review:\n",
      "I'll be looking for a new earpiece.\n",
      "Probability: [0.34160693 0.65839307]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "All in all, I'd expected a better consumer experience from Motorola.\n",
      "Original Review:\n",
      "All in all, I'd expected a better consumer experience from Motorola.\n",
      "Probability: [0.47026633 0.52973367]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Sending it back.\n",
      "Original Review:\n",
      "Sending it back.\n",
      "Probability: [0.42458818 0.57541182]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "A must study for anyone interested in the \"worst sins\" of industrial design.\n",
      "Original Review:\n",
      "A must study for anyone interested in the \"worst sins\" of industrial design.\n",
      "Probability: [0.40889197 0.59110803]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Steer clear of this product and go with the genuine Palm replacementr pens, which come in a three-pack.\n",
      "Original Review:\n",
      "Steer clear of this product and go with the genuine Palm replacementr pens, which come in a three-pack.\n",
      "Probability: [0.45141103 0.54858897]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The camera, although rated at an impressive 1.3 megapixels, renders images that fall well below expectations of such a relatively high resolution.\n",
      "Original Review:\n",
      "The camera, although rated at an impressive 1.3 megapixels, renders images that fall well below expectations of such a relatively high resolution.\n",
      "Probability: [0.38698234 0.61301766]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The loudspeaker option is great, the bumpers with the lights is very ... appealing.\n",
      "Original Review:\n",
      "The loudspeaker option is great, the bumpers with the lights is very ... appealing.\n",
      "Probability: [0.00711163 0.99288837]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The internet access was fine, it the rare instance that it worked.\n",
      "Original Review:\n",
      "The internet access was fine, it the rare instance that it worked.\n",
      "Probability: [0.16399912 0.83600088]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I've bought $5 wired headphones that sound better than these.\n",
      "Original Review:\n",
      "I've bought $5 wired headphones that sound better than these.\n",
      "Probability: [0.37929414 0.62070586]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "in addition it feels &amp; looks as if the phone is all lightweight cheap plastic.\n",
      "Original Review:\n",
      "in addition it feels &amp; looks as if the phone is all lightweight cheap plastic.\n",
      "Probability: [0.25927878 0.74072122]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "My 5-year old Nokia 2160 from Tracfone holds the charge a lot better than this.\n",
      "Original Review:\n",
      "My 5-year old Nokia 2160 from Tracfone holds the charge a lot better than this.\n",
      "Probability: [0.42034193 0.57965807]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "If you have several dozen or several hundred contacts, then imagine the fun of sending each of them one by one.\n",
      "Original Review:\n",
      "If you have several dozen or several hundred contacts, then imagine the fun of sending each of them one by one.\n",
      "Probability: [0.49309866 0.50690134]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I ordered this for sony Ericsson W810i but I think it only worked once (thats when I first used it).\n",
      "Original Review:\n",
      "I ordered this for sony Ericsson W810i but I think it only worked once (thats when I first used it).\n",
      "Probability: [0.47963834 0.52036166]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "If you like a loud buzzing to override all your conversations, then this phone is for you!\n",
      "Original Review:\n",
      "If you like a loud buzzing to override all your conversations, then this phone is for you!\n",
      "Probability: [0.34283476 0.65716524]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It was an inexpensive piece, but I would still have expected better quality.\n",
      "Original Review:\n",
      "It was an inexpensive piece, but I would still have expected better quality.\n",
      "Probability: [0.26078345 0.73921655]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "When I placed my treo into the case, not only was it NOT snug, but there was A LOT of extra room on the sides.\n",
      "Original Review:\n",
      "When I placed my treo into the case, not only was it NOT snug, but there was A LOT of extra room on the sides.\n",
      "Probability: [0.2081435 0.7918565]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I'm returning them.\n",
      "Original Review:\n",
      "I'm returning them.\n",
      "Probability: [0.2578485 0.7421515]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Save your money.... I've had this item for 11 months now.\n",
      "Original Review:\n",
      "Save your money.... I've had this item for 11 months now.\n",
      "Probability: [0.27063532 0.72936468]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "This allows the possibility of double booking for the same date and time after the first.\n",
      "Original Review:\n",
      "This allows the possibility of double booking for the same date and time after the first.\n",
      "Probability: [0.49896219 0.50103781]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Makes it easier to keep up with my bluetooth when I'm not wearing it.\n",
      "Original Review:\n",
      "Makes it easier to keep up with my bluetooth when I'm not wearing it.\n",
      "Probability: [0.36480917 0.63519083]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Plan on ordering from them again and again.\n",
      "Original Review:\n",
      "Plan on ordering from them again and again.\n",
      "Probability: [0.62628578 0.37371422]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Gets a signal when other Verizon phones won't.\n",
      "Original Review:\n",
      "Gets a signal when other Verizon phones won't.\n",
      "Probability: [0.52463548 0.47536452]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I have to use the smallest earpieces provided, but it stays on pretty well.\n",
      "Original Review:\n",
      "I have to use the smallest earpieces provided, but it stays on pretty well.\n",
      "Probability: [0.61574046 0.38425954]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "This is cool because most cases are just open there allowing the screen to get all scratched up.\n",
      "Original Review:\n",
      "This is cool because most cases are just open there allowing the screen to get all scratched up.\n",
      "Probability: [0.77462334 0.22537666]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I ended up sliding it on the edge of my pants or back pockets instead.\n",
      "Original Review:\n",
      "I ended up sliding it on the edge of my pants or back pockets instead.\n",
      "Probability: [0.7935975 0.2064025]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I had to go to a store and bought a new NOKIA phone which is working great.\n",
      "Original Review:\n",
      "I had to go to a store and bought a new NOKIA phone which is working great.\n",
      "Probability: [0.72294114 0.27705886]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Those phones are working just fine now.\n",
      "Original Review:\n",
      "Those phones are working just fine now.\n",
      "Probability: [0.53667178 0.46332822]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It definitely was not as good as my S11.\n",
      "Original Review:\n",
      "It definitely was not as good as my S11.\n",
      "Probability: [0.73235316 0.26764684]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Their Research and Development division obviously knows what they're doing.\n",
      "Original Review:\n",
      "Their Research and Development division obviously knows what they're doing.\n",
      "Probability: [0.52702094 0.47297906]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I have used several phone in two years, but this one is the best.\n",
      "Original Review:\n",
      "I have used several phone in two years, but this one is the best.\n",
      "Probability: [0.53695749 0.46304251]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "!I definitly recommend!!\n",
      "Original Review:\n",
      "!I definitly recommend!!\n",
      "Probability: [0.82117408 0.17882592]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I used bitpim (a free program you can find on the internet)to transfer data to the phone.The price of the cable was excellent.\n",
      "Original Review:\n",
      "I used bitpim (a free program you can find on the internet)to transfer data to the phone.The price of the cable was excellent.\n",
      "Probability: [0.60961226 0.39038774]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Someone shouldve invented this sooner.\n",
      "Original Review:\n",
      "Someone shouldve invented this sooner.\n",
      "Probability: [0.68072063 0.31927937]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It finds my cell phone right away when I enter the car.\n",
      "Original Review:\n",
      "It finds my cell phone right away when I enter the car.\n",
      "Probability: [0.50518386 0.49481614]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I have yet to run this new battery below two bars and that's three days without charging.\n",
      "Original Review:\n",
      "I have yet to run this new battery below two bars and that's three days without charging.\n",
      "Probability: [0.9197714 0.0802286]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Works great, when my cat attacked the phone he scratched the protective strip instead of destroying the screen.\n",
      "Original Review:\n",
      "Works great, when my cat attacked the phone he scratched the protective strip instead of destroying the screen.\n",
      "Probability: [0.5713576 0.4286424]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Much less than the jawbone I was going to replace it with.\n",
      "Original Review:\n",
      "Much less than the jawbone I was going to replace it with.\n",
      "Probability: [0.82215968 0.17784032]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "You get extra minutes so that you can carry out the call and not get cut off.\"\n",
      "Original Review:\n",
      "You get extra minutes so that you can carry out the call and not get cut off.\"\n",
      "Probability: [0.5179907 0.4820093]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Also its slim enough to fit into my alarm clock docking station without removing the case.\n",
      "Original Review:\n",
      "Also its slim enough to fit into my alarm clock docking station without removing the case.\n",
      "Probability: [0.50132621 0.49867379]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "You won't regret it!\n",
      "Original Review:\n",
      "You won't regret it!\n",
      "Probability: [0.67162616 0.32837384]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "My Sanyo has survived dozens of drops on blacktop without ill effect.\n",
      "Original Review:\n",
      "My Sanyo has survived dozens of drops on blacktop without ill effect.\n",
      "Probability: [0.63476026 0.36523974]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Bluetooth range is good - a few days ago I left my phone in the trunk, got a call, and carried the conversation without a hitch.\n",
      "Original Review:\n",
      "Bluetooth range is good - a few days ago I left my phone in the trunk, got a call, and carried the conversation without a hitch.\n",
      "Probability: [0.55518042 0.44481958]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "You can't beat the price on these.\n",
      "Original Review:\n",
      "You can't beat the price on these.\n",
      "Probability: [0.86291761 0.13708239]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Because both ears are occupied, background is not distracting at all.\n",
      "Original Review:\n",
      "Because both ears are occupied, background is not distracting at all.\n",
      "Probability: [0.84119733 0.15880267]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Will order from them again!\n",
      "Original Review:\n",
      "Will order from them again!\n",
      "Probability: [0.5573696 0.4426304]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "In the span of an hour, I had two people exclaim \"Whoa - is that the new phone on TV?!?\n",
      "Original Review:\n",
      "In the span of an hour, I had two people exclaim \"Whoa - is that the new phone on TV?!?\n",
      "Probability: [0.59944818 0.40055182]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Very satisifed with that.\n",
      "Original Review:\n",
      "Very satisifed with that.\n",
      "Probability: [0.50100453 0.49899547]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I've dropped my phone more times than I can say, even on concrete and my phone is still great (knock on wood!).\n",
      "Original Review:\n",
      "I've dropped my phone more times than I can say, even on concrete and my phone is still great (knock on wood!).\n",
      "Probability: [0.650348 0.349652]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      ":-)Oh, the charger seems to work fine.\n",
      "Original Review:\n",
      ":-)Oh, the charger seems to work fine.\n",
      "Probability: [0.52520242 0.47479758]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      ")Setup couldn't have been simpler.\n",
      "Original Review:\n",
      ")Setup couldn't have been simpler.\n",
      "Probability: [0.84826336 0.15173664]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I was able to do voice dialing in the car with no problem.\n",
      "Original Review:\n",
      "I was able to do voice dialing in the car with no problem.\n",
      "Probability: [0.57070008 0.42929992]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "My phone doesn't slide around my car now and the grip prevents my phone from slipping out of my hand.\n",
      "Original Review:\n",
      "My phone doesn't slide around my car now and the grip prevents my phone from slipping out of my hand.\n",
      "Probability: [0.73327227 0.26672773]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It is so small and you don't even realize that it is there after a while of getting used to it.\n",
      "Original Review:\n",
      "It is so small and you don't even realize that it is there after a while of getting used to it.\n",
      "Probability: [0.6689042 0.3310958]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "This is definitely a must have if your state does not allow cell phone usage while driving.\n",
      "Original Review:\n",
      "This is definitely a must have if your state does not allow cell phone usage while driving.\n",
      "Probability: [0.77876297 0.22123703]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I own 2 of these cases and would order another.\n",
      "Original Review:\n",
      "I own 2 of these cases and would order another.\n",
      "Probability: [0.54575161 0.45424839]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I'm still infatuated with this phone.\n",
      "Original Review:\n",
      "I'm still infatuated with this phone.\n",
      "Probability: [0.63852498 0.36147502]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "They keep getting better and better (this is my third one and I've had numerous Palms too).\n",
      "Original Review:\n",
      "They keep getting better and better (this is my third one and I've had numerous Palms too).\n",
      "Probability: [0.50502573 0.49497427]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Linked to my phone without effort.\n",
      "Original Review:\n",
      "Linked to my phone without effort.\n",
      "Probability: [0.69218999 0.30781001]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The stories were as unbelievable as the actors.  \n",
      "Original Review:\n",
      "The stories were as unbelievable as the actors.  \n",
      "Probability: [0.27658397 0.72341603]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "And, FINALLY, after all that, we get to an ending that would've been great had it been handled by competent people and not Jerry Falwell.  \n",
      "Original Review:\n",
      "And, FINALLY, after all that, we get to an ending that would've been great had it been handled by competent people and not Jerry Falwell.  \n",
      "Probability: [0.22229144 0.77770856]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I'm glad this pretentious piece of s*** didn't do as planned by the Dodge stratus Big Shots... It's gonna help movie makers who aren't in the very restrained \"movie business\" of Québec.  \n",
      "Original Review:\n",
      "I'm glad this pretentious piece of s*** didn't do as planned by the Dodge stratus Big Shots... It's gonna help movie makers who aren't in the very restrained \"movie business\" of Québec.  \n",
      "Probability: [0.4870219 0.5129781]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I know that Jim O'Connor was very energetic and that nobody could be as much as him, but George was well dull.  \n",
      "Original Review:\n",
      "I know that Jim O'Connor was very energetic and that nobody could be as much as him, but George was well dull.  \n",
      "Probability: [0.49040124 0.50959876]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "You can find better movies at youtube.  \n",
      "Original Review:\n",
      "You can find better movies at youtube.  \n",
      "Probability: [0.2226736 0.7773264]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Never heard of any of them except Cole who was totally unbelievable in the part.  \n",
      "Original Review:\n",
      "Never heard of any of them except Cole who was totally unbelievable in the part.  \n",
      "Probability: [0.42451946 0.57548054]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The lead man is charisma-free.  \n",
      "Original Review:\n",
      "The lead man is charisma-free.  \n",
      "Probability: [0.25723096 0.74276904]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "He can bore you to pieces, and kill the momentum of a movie, quicker than anyone else.  \n",
      "Original Review:\n",
      "He can bore you to pieces, and kill the momentum of a movie, quicker than anyone else.  \n",
      "Probability: [0.4805373 0.5194627]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Im big fan of RPG games too, but this movie, its a disgrace to any self-respecting RPGer there is.  \n",
      "Original Review:\n",
      "Im big fan of RPG games too, but this movie, its a disgrace to any self-respecting RPGer there is.  \n",
      "Probability: [0.43779584 0.56220416]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The acting by the whole cast could be put on a scale and balanced perfectly between overacting and underacting.  \n",
      "Original Review:\n",
      "The acting by the whole cast could be put on a scale and balanced perfectly between overacting and underacting.  \n",
      "Probability: [0.1253401 0.8746599]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "If only someone involved with it knew how to string together narrative!  \n",
      "Original Review:\n",
      "If only someone involved with it knew how to string together narrative!  \n",
      "Probability: [0.21820661 0.78179339]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Both films are terrible, but to the credit of the 1986 version, it was watchable.  \n",
      "Original Review:\n",
      "Both films are terrible, but to the credit of the 1986 version, it was watchable.  \n",
      "Probability: [0.36956061 0.63043939]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Not only did it only confirm that the film would be unfunny and generic, but it also managed to give away the ENTIRE movie; and I'm not exaggerating - every moment, every plot point, every joke is told in the trailer.  \n",
      "Original Review:\n",
      "Not only did it only confirm that the film would be unfunny and generic, but it also managed to give away the ENTIRE movie; and I'm not exaggerating - every moment, every plot point, every joke is told in the trailer.  \n",
      "Probability: [0.43135064 0.56864936]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Which has more depth and character than the man underneath it.  \n",
      "Original Review:\n",
      "Which has more depth and character than the man underneath it.  \n",
      "Probability: [0.07370494 0.92629506]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Rating: 1 out of 10.  \n",
      "Original Review:\n",
      "Rating: 1 out of 10.  \n",
      "Probability: [0.27516657 0.72483343]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "A Lassie movie which should have been \"put to sleep\".... FOREVER.  \n",
      "Original Review:\n",
      "A Lassie movie which should have been \"put to sleep\".... FOREVER.  \n",
      "Probability: [0.37590137 0.62409863]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "If you do go see this movie, bring a pillow or a girlfriend/boyfriend to keep you occupied through out.  \n",
      "Original Review:\n",
      "If you do go see this movie, bring a pillow or a girlfriend/boyfriend to keep you occupied through out.  \n",
      "Probability: [0.42200428 0.57799572]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It crackles with an unpredictable, youthful energy - but honestly, i found it hard to follow and concentrate on it meanders so badly.  \n",
      "Original Review:\n",
      "It crackles with an unpredictable, youthful energy - but honestly, i found it hard to follow and concentrate on it meanders so badly.  \n",
      "Probability: [0.47869636 0.52130364]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "To those who find this movie intelligent or even masterful, I can only say - it's your intelligence and your imagination you obviously used to try and make some sense of this pitiful attempt (it's in our human nature to try and make sense of things) .  \n",
      "Original Review:\n",
      "To those who find this movie intelligent or even masterful, I can only say - it's your intelligence and your imagination you obviously used to try and make some sense of this pitiful attempt (it's in our human nature to try and make sense of things) .  \n",
      "Probability: [0.35241719 0.64758281]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I've seen soap operas more intelligent than this movie.  \n",
      "Original Review:\n",
      "I've seen soap operas more intelligent than this movie.  \n",
      "Probability: [0.48849081 0.51150919]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I felt asleep the first time I watched it, so I can recommend it for insomniacs.  \n",
      "Original Review:\n",
      "I felt asleep the first time I watched it, so I can recommend it for insomniacs.  \n",
      "Probability: [0.49579965 0.50420035]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It is an insane game.  \n",
      "Original Review:\n",
      "It is an insane game.  \n",
      "Probability: [0.84802362 0.15197638]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The film's sole bright spot was Jonah Hill (who will look almost unrecognizable to fans of the recent Superbad due to the amount of weight he lost in the interim).  \n",
      "Original Review:\n",
      "The film's sole bright spot was Jonah Hill (who will look almost unrecognizable to fans of the recent Superbad due to the amount of weight he lost in the interim).  \n",
      "Probability: [0.61009489 0.38990511]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I believe every one should see this movie as I think few people outside of South Africa understand its past and what is being attempted in the Truth and Reconciliation process.  \n",
      "Original Review:\n",
      "I believe every one should see this movie as I think few people outside of South Africa understand its past and what is being attempted in the Truth and Reconciliation process.  \n",
      "Probability: [0.50126215 0.49873785]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It features an outlandish array of memorable, psychotic but lovable nuts.  \n",
      "Original Review:\n",
      "It features an outlandish array of memorable, psychotic but lovable nuts.  \n",
      "Probability: [0.64623156 0.35376844]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Mark my words, this is one of those cult films like Evil Dead 2 or Phantasm that people will still be discovering and falling in love with 20, 30, 40 years down the line.  \n",
      "Original Review:\n",
      "Mark my words, this is one of those cult films like Evil Dead 2 or Phantasm that people will still be discovering and falling in love with 20, 30, 40 years down the line.  \n",
      "Probability: [0.61067587 0.38932413]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Still, it was the SETS that got a big \"10\" on my \"oy-vey\" scale.  \n",
      "Original Review:\n",
      "Still, it was the SETS that got a big \"10\" on my \"oy-vey\" scale.  \n",
      "Probability: [0.51329738 0.48670262]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "This is the kind of money that is wasted properly.  \n",
      "Original Review:\n",
      "This is the kind of money that is wasted properly.  \n",
      "Probability: [0.66909406 0.33090594]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I struggle to find anything bad to say about it.  \n",
      "Original Review:\n",
      "I struggle to find anything bad to say about it.  \n",
      "Probability: [0.93063247 0.06936753]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The movie had you on the edge of your seat and made you somewhat afraid to go to your car at the end of the night.  \n",
      "Original Review:\n",
      "The movie had you on the edge of your seat and made you somewhat afraid to go to your car at the end of the night.  \n",
      "Probability: [0.6443033 0.3556967]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "How can anyone in their right mind ask for anything more from a movie than this?  \n",
      "Original Review:\n",
      "How can anyone in their right mind ask for anything more from a movie than this?  \n",
      "Probability: [0.82171973 0.17828027]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "There is, however, some pretty good acting (at least, for this type of film).  \n",
      "Original Review:\n",
      "There is, however, some pretty good acting (at least, for this type of film).  \n",
      "Probability: [0.5039873 0.4960127]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I have seen many movies starring Jaclyn Smith, but my god this was one of her best, though it came out 12 years ago.  \n",
      "Original Review:\n",
      "I have seen many movies starring Jaclyn Smith, but my god this was one of her best, though it came out 12 years ago.  \n",
      "Probability: [0.50920461 0.49079539]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Still, it makes up for all of this with a super ending that depicts a great sea vessel being taken out by the mighty frost.  \n",
      "Original Review:\n",
      "Still, it makes up for all of this with a super ending that depicts a great sea vessel being taken out by the mighty frost.  \n",
      "Probability: [0.50537524 0.49462476]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The last 15 minutes of movie are also not bad as well.  \n",
      "Original Review:\n",
      "The last 15 minutes of movie are also not bad as well.  \n",
      "Probability: [0.88492662 0.11507338]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Don't miss it.  \n",
      "Original Review:\n",
      "Don't miss it.  \n",
      "Probability: [0.59381114 0.40618886]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Waste your money on this game.  \n",
      "Original Review:\n",
      "Waste your money on this game.  \n",
      "Probability: [0.98921501 0.01078499]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Go rent it.  \n",
      "Original Review:\n",
      "Go rent it.  \n",
      "Probability: [0.5538976 0.4461024]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "But this understated film leaves a lasting impression.  \n",
      "Original Review:\n",
      "But this understated film leaves a lasting impression.  \n",
      "Probability: [0.5556361 0.4443639]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "***SPOILERS*** Whatever else can (or can't) be said about it, SURFACE is superbly crafted.  \n",
      "Original Review:\n",
      "***SPOILERS*** Whatever else can (or can't) be said about it, SURFACE is superbly crafted.  \n",
      "Probability: [0.50525584 0.49474416]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "But I thought his acting was skilled.  \n",
      "Original Review:\n",
      "But I thought his acting was skilled.  \n",
      "Probability: [0.5308519 0.4691481]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I didn't realize how wonderful the short really is until the last two scenes.  \n",
      "Original Review:\n",
      "I didn't realize how wonderful the short really is until the last two scenes.  \n",
      "Probability: [0.67728495 0.32271505]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I liked this movie way too much.  \n",
      "Original Review:\n",
      "I liked this movie way too much.  \n",
      "Probability: [0.68285607 0.31714393]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "And there wasn't a single sour note struck acting-wise, either; some surprisingly solid casting, here.  \n",
      "Original Review:\n",
      "And there wasn't a single sour note struck acting-wise, either; some surprisingly solid casting, here.  \n",
      "Probability: [0.67358288 0.32641712]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It actually turned out to be pretty decent as far as B-list horror/suspense films go.  \n",
      "Original Review:\n",
      "It actually turned out to be pretty decent as far as B-list horror/suspense films go.  \n",
      "Probability: [0.71748554 0.28251446]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "\" In fact, it's hard to remember that the part of Ray Charles is being acted, and not played by the man himself.  \n",
      "Original Review:\n",
      "\" In fact, it's hard to remember that the part of Ray Charles is being acted, and not played by the man himself.  \n",
      "Probability: [0.50723314 0.49276686]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The film gives meaning to the phrase, \"Never in the history of human conflict has so much been owed by so many to so few.  \n",
      "Original Review:\n",
      "The film gives meaning to the phrase, \"Never in the history of human conflict has so much been owed by so many to so few.  \n",
      "Probability: [0.64892284 0.35107716]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Tom Wilkinson broke my heart at the end... and everyone else's judging by the amount of fumbling for hankies and hands going up to faces among males and females alike.  \n",
      "Original Review:\n",
      "Tom Wilkinson broke my heart at the end... and everyone else's judging by the amount of fumbling for hankies and hands going up to faces among males and females alike.  \n",
      "Probability: [0.79888506 0.20111494]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Not much dialogue, not much music, the whole film was shot as elaborately and aesthetically like a sculpture.  \n",
      "Original Review:\n",
      "Not much dialogue, not much music, the whole film was shot as elaborately and aesthetically like a sculpture.  \n",
      "Probability: [0.59736418 0.40263582]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I must say I have taped most of the episodes and i find myself watching them over and over again.  \n",
      "Original Review:\n",
      "I must say I have taped most of the episodes and i find myself watching them over and over again.  \n",
      "Probability: [0.74048358 0.25951642]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Some applause should be given to the \"prelude\" however.  \n",
      "Original Review:\n",
      "Some applause should be given to the \"prelude\" however.  \n",
      "Probability: [0.74961127 0.25038873]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The characters were all funny and had the peculiarity of not having a true lead character.  \n",
      "Original Review:\n",
      "The characters were all funny and had the peculiarity of not having a true lead character.  \n",
      "Probability: [0.51776451 0.48223549]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "You wont regret it!  \n",
      "Original Review:\n",
      "You wont regret it!  \n",
      "Probability: [0.65133463 0.34866537]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I'm glad the film didn't go for the most obvious choice, as a lesser film certainly would have.  \n",
      "Original Review:\n",
      "I'm glad the film didn't go for the most obvious choice, as a lesser film certainly would have.  \n",
      "Probability: [0.66553571 0.33446429]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I'd advise anyone to go and see it.  \n",
      "Original Review:\n",
      "I'd advise anyone to go and see it.  \n",
      "Probability: [0.56354629 0.43645371]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I would have casted her in that role after ready the script.  \n",
      "Original Review:\n",
      "I would have casted her in that role after ready the script.  \n",
      "Probability: [0.70556674 0.29443326]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Any grandmother can make a roasted chicken better than this one.\n",
      "Original Review:\n",
      "Any grandmother can make a roasted chicken better than this one.\n",
      "Probability: [0.12741683 0.87258317]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "it was a drive to get there.\n",
      "Original Review:\n",
      "it was a drive to get there.\n",
      "Probability: [0.49764546 0.50235454]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Before I go in to why I gave a 1 star rating please know that this was my third time eating at Bachi burger before writing a review.\n",
      "Original Review:\n",
      "Before I go in to why I gave a 1 star rating please know that this was my third time eating at Bachi burger before writing a review.\n",
      "Probability: [0.49737939 0.50262061]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "We've have gotten a much better service from the pizza place next door than the services we received from this restaurant.\n",
      "Original Review:\n",
      "We've have gotten a much better service from the pizza place next door than the services we received from this restaurant.\n",
      "Probability: [0.37937173 0.62062827]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "There is really nothing for me at postinos, hope your experience is better\n",
      "Original Review:\n",
      "There is really nothing for me at postinos, hope your experience is better\n",
      "Probability: [0.356608 0.643392]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Ordered burger rare came in we'll done.\n",
      "Original Review:\n",
      "Ordered burger rare came in we'll done.\n",
      "Probability: [0.182552 0.817448]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "say bye bye to your tip lady!\n",
      "Original Review:\n",
      "say bye bye to your tip lady!\n",
      "Probability: [0.29162288 0.70837712]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "very tough and very short on flavor!\n",
      "Original Review:\n",
      "very tough and very short on flavor!\n",
      "Probability: [0.36425092 0.63574908]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I've had better bagels from the grocery store.\n",
      "Original Review:\n",
      "I've had better bagels from the grocery store.\n",
      "Probability: [0.45754519 0.54245481]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "too bad cause I know it's family owned, I really wanted to like this place.\n",
      "Original Review:\n",
      "too bad cause I know it's family owned, I really wanted to like this place.\n",
      "Probability: [0.09828923 0.90171077]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The service here leaves a lot to be desired.\n",
      "Original Review:\n",
      "The service here leaves a lot to be desired.\n",
      "Probability: [0.26877684 0.73122316]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Ordered an appetizer and took 40 minutes and then the pizza another 10 minutes.\n",
      "Original Review:\n",
      "Ordered an appetizer and took 40 minutes and then the pizza another 10 minutes.\n",
      "Probability: [0.40768433 0.59231567]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I've lived here since 1979 and this was the first (and last) time I've stepped foot into this place.\n",
      "Original Review:\n",
      "I've lived here since 1979 and this was the first (and last) time I've stepped foot into this place.\n",
      "Probability: [0.42802879 0.57197121]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I got home to see the driest damn wings ever!\n",
      "Original Review:\n",
      "I got home to see the driest damn wings ever!\n",
      "Probability: [0.20121989 0.79878011]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The chicken dishes are OK, the beef is like shoe leather.\n",
      "Original Review:\n",
      "The chicken dishes are OK, the beef is like shoe leather.\n",
      "Probability: [0.09366192 0.90633808]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "This place deserves one star and 90% has to do with the food.\n",
      "Original Review:\n",
      "This place deserves one star and 90% has to do with the food.\n",
      "Probability: [0.35305754 0.64694246]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I have been to very few places to eat that under no circumstances would I ever return to, and this tops the list.\n",
      "Original Review:\n",
      "I have been to very few places to eat that under no circumstances would I ever return to, and this tops the list.\n",
      "Probability: [0.44246511 0.55753489]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It was packed!!\n",
      "Original Review:\n",
      "It was packed!!\n",
      "Probability: [0.21388028 0.78611972]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "We waited an hour for what was a breakfast I could have done 100 times better at home.\n",
      "Original Review:\n",
      "We waited an hour for what was a breakfast I could have done 100 times better at home.\n",
      "Probability: [0.49061753 0.50938247]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Spend your money and time some place else.\n",
      "Original Review:\n",
      "Spend your money and time some place else.\n",
      "Probability: [0.484592 0.515408]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It wasn't busy at all and now we know why.\n",
      "Original Review:\n",
      "It wasn't busy at all and now we know why.\n",
      "Probability: [0.47714628 0.52285372]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It really is impressive that the place hasn't closed down.\n",
      "Original Review:\n",
      "It really is impressive that the place hasn't closed down.\n",
      "Probability: [0.21713835 0.78286165]\n",
      "Predicted: 1.0\n",
      "Actual: 0.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "If you want a sandwich just go to any Firehouse!!!!!\n",
      "Original Review:\n",
      "If you want a sandwich just go to any Firehouse!!!!!\n",
      "Probability: [0.52163457 0.47836543]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The only thing I did like was the prime rib and dessert section.\n",
      "Original Review:\n",
      "The only thing I did like was the prime rib and dessert section.\n",
      "Probability: [0.67619004 0.32380996]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "So good I am going to have to review this place twice - once hereas a tribute to the place and once as a tribute to an event held here last night.\n",
      "Original Review:\n",
      "So good I am going to have to review this place twice - once hereas a tribute to the place and once as a tribute to an event held here last night.\n",
      "Probability: [0.58874594 0.41125406]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Bacon is hella salty.\n",
      "Original Review:\n",
      "Bacon is hella salty.\n",
      "Probability: [0.66869907 0.33130093]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I don't know what kind it is but they have the best iced tea.\n",
      "Original Review:\n",
      "I don't know what kind it is but they have the best iced tea.\n",
      "Probability: [0.58854447 0.41145553]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "One of the few places in Phoenix that I would definately go back to again .\n",
      "Original Review:\n",
      "One of the few places in Phoenix that I would definately go back to again .\n",
      "Probability: [0.62365835 0.37634165]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I found this place by accident and I could not be happier.\n",
      "Original Review:\n",
      "I found this place by accident and I could not be happier.\n",
      "Probability: [0.61822147 0.38177853]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "You cant go wrong with any of the food here.\n",
      "Original Review:\n",
      "You cant go wrong with any of the food here.\n",
      "Probability: [0.8756883 0.1243117]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "If you're not familiar, check it out.\n",
      "Original Review:\n",
      "If you're not familiar, check it out.\n",
      "Probability: [0.50328529 0.49671471]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I did not expect this to be so good!\n",
      "Original Review:\n",
      "I did not expect this to be so good!\n",
      "Probability: [0.81384013 0.18615987]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Never had anything to complain about here.\n",
      "Original Review:\n",
      "Never had anything to complain about here.\n",
      "Probability: [0.7497904 0.2502096]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The only good thing was our waiter, he was very helpful and kept the bloddy mary's coming.\n",
      "Original Review:\n",
      "The only good thing was our waiter, he was very helpful and kept the bloddy mary's coming.\n",
      "Probability: [0.6013804 0.3986196]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Hands down my favorite Italian restaurant!\n",
      "Original Review:\n",
      "Hands down my favorite Italian restaurant!\n",
      "Probability: [0.56840944 0.43159056]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The sweet potato tots were good but the onion rings were perfection or as close as I have had.\n",
      "Original Review:\n",
      "The sweet potato tots were good but the onion rings were perfection or as close as I have had.\n",
      "Probability: [0.50009101 0.49990899]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "If you stay in Vegas you must get breakfast here at least once.\n",
      "Original Review:\n",
      "If you stay in Vegas you must get breakfast here at least once.\n",
      "Probability: [0.63388864 0.36611136]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "He came running after us when he realized my husband had left his sunglasses on the table.\n",
      "Original Review:\n",
      "He came running after us when he realized my husband had left his sunglasses on the table.\n",
      "Probability: [0.80092901 0.19907099]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The Veggitarian platter is out of this world!\n",
      "Original Review:\n",
      "The Veggitarian platter is out of this world!\n",
      "Probability: [0.89203985 0.10796015]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Food was really good and I got full petty fast.\n",
      "Original Review:\n",
      "Food was really good and I got full petty fast.\n",
      "Probability: [0.69481025 0.30518975]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Plus, it's only 8 bucks.\n",
      "Original Review:\n",
      "Plus, it's only 8 bucks.\n",
      "Probability: [0.5184836 0.4815164]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The wontons were thin, not thick and chewy, almost melt in your mouth.\n",
      "Original Review:\n",
      "The wontons were thin, not thick and chewy, almost melt in your mouth.\n",
      "Probability: [0.50218933 0.49781067]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "It was just not a fun experience.\n",
      "Original Review:\n",
      "It was just not a fun experience.\n",
      "Probability: [0.79715903 0.20284097]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Cant say enough good things about this place.\n",
      "Original Review:\n",
      "Cant say enough good things about this place.\n",
      "Probability: [0.78098388 0.21901612]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The lighting is just dark enough to set the mood.\n",
      "Original Review:\n",
      "The lighting is just dark enough to set the mood.\n",
      "Probability: [0.50465521 0.49534479]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "Would come back again if I had a sushi craving while in Vegas.\n",
      "Original Review:\n",
      "Would come back again if I had a sushi craving while in Vegas.\n",
      "Probability: [0.61380857 0.38619143]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The service was outshining & I definitely recommend the Halibut.\n",
      "Original Review:\n",
      "The service was outshining & I definitely recommend the Halibut.\n",
      "Probability: [0.71125368 0.28874632]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "The black eyed peas and sweet potatoes... UNREAL!\n",
      "Original Review:\n",
      "The black eyed peas and sweet potatoes... UNREAL!\n",
      "Probability: [0.72161339 0.27838661]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I didn't know pulled pork could be soooo delicious.\n",
      "Original Review:\n",
      "I didn't know pulled pork could be soooo delicious.\n",
      "Probability: [0.76973447 0.23026553]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n",
      "Butchered Review:\n",
      "I could eat their bruschetta all day it is devine.\n",
      "Original Review:\n",
      "I could eat their bruschetta all day it is devine.\n",
      "Probability: [0.58456786 0.41543214]\n",
      "Predicted: 0.0\n",
      "Actual: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print(\"Butchered Review:\")\n",
    "    print(reviews_string.split(\"\\n\")[i])\n",
    "    #print('\\n')\n",
    "    print(\"Original Review:\")\n",
    "    print(reviews_string.split(\"\\n\")[i])\n",
    "    #print('\\n')\n",
    "    print(\"Probability:\", probas[i])\n",
    "    print(\"Predicted:\", train_predictions[i])\n",
    "    print(\"Actual:\", y_tr_N[i])\n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "af1f6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_string = \"Plan on ordering from them again and again.\"\n",
    "#preprocess_string(test_string)\n",
    "reviews_string3 = test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "b291df0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan on ordering from them again and again '"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = remove_non_alpha_num(reviews_string3)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "161aec85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan on ordering from them again and again'"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = correct_spelling(reviews_string3)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744bf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456008a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eae76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "7bd75061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan on order from them again and again'"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = lemmatize_words(reviews_string3)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "2b5c2234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan order'"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_string3 = remove_stop_words(reviews_string3, stop_words)\n",
    "reviews_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
